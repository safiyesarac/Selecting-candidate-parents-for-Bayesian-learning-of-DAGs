# mybnexp/coverage.py
def get_true_parents(model_file):  
    import bnlearn as bn

# Load a predefined Bayesian network structure
    model = bn.import_DAG(model_file)
    adjmat = model["adjmat"]

    # Get the list of node names (assumed to be the same in the DataFrame index and columns)
    nodes = list(adjmat.columns)
    print(adjmat.columns)



    # Build a dictionary mapping each node to its list of parent nodes.
    model_dict = {}
    for node in nodes:
        # For each node, find all source nodes for which the value is True.
        # The expression `adjmat[node] == True` returns a boolean Series;
        # its index are the source node names.
        parent_nodes = list(adjmat.index[adjmat[node] == True])
        model_dict[node] = parent_nodes

    # 3. Define a conversion function that works without needing a desired order.
    def convert_bn_to_indices(model_dict, ordered_node_list):
        """
        Convert a BN to a dictionary mapping node indices to parent indices,
        respecting the user-supplied 'ordered_node_list'.
        """
        node_names = ordered_node_list  # Use the given order
        name_to_idx = {name: i for i, name in enumerate(node_names)}

        bn_dict = {}
        for name in node_names:
            parents = model_dict.get(name, [])
            parent_indices = tuple(name_to_idx[p] for p in parents)
            bn_dict[name_to_idx[name]] = parent_indices

        return bn_dict

    ordered_nodes = list(adjmat.columns)
    return convert_bn_to_indices(model_dict, ordered_nodes)
# sumu and related modules
def coverage_fraction(candidate_parents, sampled_dags):
    """
    Compute fraction of sampled_dags that are covered by candidate_parents.

    Coverage criterion:
        For every node v, the DAG's parents for v are a subset of candidate_parents[v].
    """
    if not sampled_dags:
        return None
    count_covered = 0
    total = len(sampled_dags)

    for dag in sampled_dags:
        covered = True
        for node, parents in dag.items():
            if not parents.issubset(candidate_parents[node]):
                covered = False
                break
        if covered:
            count_covered += 1
    
    return count_covered / total


def dag_nodes_covered(dag_ref, candidate_parents):
    """
    node-by-node coverage check:
    For each node i in dag_ref, let ref_par = set(dag_ref[i]).
    We see if candidate_parents[i] has a set that equals ref_par.
    If yes => node i is covered, else not.
    coverage => True only if every node i is covered.
    """
    for node, ref_pa_list in dag_ref.items():
        ref_set = set(ref_pa_list)

        # Grab what the heuristic returned for this node
        csets = candidate_parents.get(node, None)
        if csets is None:
            # No candidate parents at all
            return False

        # If the heuristic returns a *single* tuple (e.g. (3,4,5)),
        # we make it a list of one element => [(3,4,5)]
        if isinstance(csets, tuple):
            csets = [csets]

        # If it might be a single int instead (e.g. 4), wrap that as well
        elif isinstance(csets, int):
            csets = [[csets]]

        # Now csets should be a list of "parent sets."
        # (e.g. [ (3,4,5) ] or [ [4,5], [6,7] ], etc.)

        found_match = False
        for cset in csets:
            # cset might be a tuple or list; convert to a set of integers
            if not isinstance(cset, set):
                cset = set(cset)

            if cset == ref_set:
                found_match = True
                break

        if not found_match:
            return False

    # If we never returned False, all nodes had a matching parent set
    return True

dag_nodes_covered({1: [8, 2, 3], 7: [6], 0: [], 2: [], 3: [], 4: [], 5: [], 6: [], 8: []},{1: [8, 2, 3,7], 7: [6], 0: [], 2: [], 3: [], 4: [], 5: [], 6: [], 8: []})
print(dag_nodes_covered)# mybnexp/data_io.py

import logging
import pandas as pd
import sumu


def read_csv_as_sumu_data(csv_path, skiprows=None, discrete=True):
    """
    Reads a CSV file into a sumu.Data object.
    
    Args:
        csv_path (str): Path to CSV file.
        skiprows (list[int] or None): Rows to skip in the CSV (e.g. [1] if row2 is metadata).
        discrete (bool): Whether the data is discrete for sumu.
    
    Returns:
        sumu.Data
    """
    df = pd.read_csv(csv_path, skiprows=skiprows)
    data_matrix = df.values
    logging.info(f"Loaded CSV data from {csv_path} with shape {data_matrix.shape}")
    return sumu.Data(data_matrix, discrete=discrete)


def parse_dag_line(line: str) -> dict:
    """
    Given a line like:
        '0 <- {}, 1 <- {3}, 2 <- {3}, 3 <- {}, ...'
    return a dict {0: set(), 1: {3}, 2: {3}, 3: set(), ...}.
    """
    dag = {}
    chunks = line.split("},")
    for chunk in chunks:
        chunk = chunk.strip()
        if not chunk:
            continue
        if not chunk.endswith("}"):
            chunk += "}"
        if "<-" not in chunk:
            continue

        node_str, parents_str = chunk.split("<-")
        node_str = node_str.strip()
        parents_str = parents_str.strip()

        # Remove outer braces
        if parents_str.startswith("{"):
            parents_str = parents_str[1:]
        if parents_str.endswith("}"):
            parents_str = parents_str[:-1]

        if parents_str.strip():
            parent_list = [p.strip() for p in parents_str.split(",") if p.strip()]
            parents = set(int(p) for p in parent_list)
        else:
            parents = set()

        dag[int(node_str)] = parents
    return dag


def parse_dag_file(dag_file: str) -> list:
    """
    Read each line from dag_file, parse into a DAG dict: {node: set_of_parents}.
    Returns a list of such DAGs.
    """
    all_dags = []
    with open(dag_file, "r") as f:
        for line_no, line in enumerate(f, start=1):
            line = line.strip()
            if not line:
                continue
            dag = parse_dag_line(line)
            if dag:
                all_dags.append(dag)
            else:
                logging.warning(f"Line {line_no} in {dag_file} was empty or invalid.")
                return 
    logging.info(f"Parsed {len(all_dags)} DAGs from {dag_file}")
    return all_dags


def parse_gobnilp_jkl(file_path: str) -> dict:
    """
    Parse a Gobnilp .jkl file.
    Returns a dict of node -> [ (score, (parents...)), (score, (parents...)), ... ].
    """
    scores = {}
    current_node = None

    with open(file_path, 'r') as file:
        for line in file:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) == 1 and parts[0].isdigit():
                # Possibly a metadata line, skip
                continue
            elif len(parts) == 2 and not line.startswith("-"):
                # Node header line (e.g., "6 64")
                try:
                    current_node = int(parts[0])
                    scores[current_node] = []
                except ValueError:
                    logging.warning(f"Unexpected node header: {line}")
            elif current_node is not None and len(parts) >= 2:
                try:
                    score = float(parts[0])
                    num_parents = int(parts[1])
                    parent_nodes = tuple(map(int, parts[2:])) if num_parents > 0 else ()
                    scores[current_node].append((score, parent_nodes))
                except ValueError:
                    logging.warning(f"Invalid line for score/parents: {line}")
            else:
                logging.warning(f"Unrecognized line: {line}")

    logging.info(f"Parsed Gobnilp .jkl file: {file_path}, found {len(scores)} nodes.")
    return scores
import bnlearn as bn
   
import pandas as pd
from pgmpy.readwrite import BIFReader

def sample_datapoints_from_model(model_file, n,csv_file, dat_file):


    # Load a predefined Bayesian network structure
    model = bn.import_DAG(model_file)

    model_data = bn.sampling(model, n=n)
    df=pd.DataFrame(model_data)
    columns = [str(i) for i in range(len(df.columns))]
    print(columns)
    data =[df[col].nunique() for col in df.columns]
    data=[data]
    # data = [[2] *( len(columns)+0)]
    # Convert to DataFrame
    df_arity = pd.DataFrame(data, columns=columns)

    column_mapping = {old: new for old, new in zip(df.columns, df_arity.columns)}
    df = df.rename(columns=column_mapping)

    # Now, combine the data as before
    df_combined_correct = pd.concat([df_arity, df], ignore_index=True)
    df_combined_correct.to_csv(csv_file, index=False)


    # Combine the arity information (first row) with the rest of the dataset
    df_combined_correct = pd.concat([df_arity, df])
    # Save the DataFrame to a CSV file for inspection or future use
    #df_arity.to_csv("data/original_hailfinder_dataset.csv", index=False)
    # Append the arity row (df_arity) on top of the data_samples
    df_combined = pd.concat([df_arity, df], ignore_index=True)

    # Save the combined dataset to a CSV file
    df_combined.to_csv(dat_file, index=False, sep=' ')


def save_data(df,csv_file, dat_file):
    columns = [str(i) for i in range(len(df.columns))]
    print(columns)
    data =[df[col].nunique() for col in df.columns]
    data=[data]
    # data = [[2] *( len(columns)+0)]
    # Convert to DataFrame
    df_arity = pd.DataFrame(data, columns=columns)

    column_mapping = {old: new for old, new in zip(df.columns, df_arity.columns)}
    df = df.rename(columns=column_mapping)

    # Now, combine the data as before
    df_combined_correct = pd.concat([df_arity, df], ignore_index=True)
    df_combined_correct.to_csv(csv_file, index=False)


    # Combine the arity information (first row) with the rest of the dataset
    df_combined_correct = pd.concat([df_arity, df])
    # Save the DataFrame to a CSV file for inspection or future use
    #df_arity.to_csv("data/original_hailfinder_dataset.csv", index=False)
    # Append the arity row (df_arity) on top of the data_samples
    df_combined = pd.concat([df_arity, df], ignore_index=True)

    # Save the combined dataset to a CSV file
    df_combined.to_csv(dat_file, index=False, sep=' ')    
    
def compute_bdeu_scores(dat_file,jkl_file):
    import subprocess

    # Define the command as a list
    command = [
        "python3",
        "/home/gulce/Downloads/thesis/pygobnilp-1.0/rungobnilp.py",
       dat_file,
        "--output_scores", jkl_file,
        "--score", "BDeu",
        "--nopruning",# "--palim","1",
        "--end", "local scores"
    ]

    # Specify the output file
    output_file = "command_output.txt"

    # Run the command and write its output to a file
    with open(output_file, "w") as file:
        try:
            result = subprocess.run(command, check=True, text=True, stdout=file, stderr=subprocess.PIPE)
            print("Command executed successfully! Output written to", output_file)
        except subprocess.CalledProcessError as e:
            print("An error occurred while executing the command.")
            print("Error message:", e.stderr)
sample_datapoints_from_model("data/barleyfungal/barleyfungal.bif",10000, "data/barleyfungal/barleyfungal_10000.csv","data/barleyfungal/barleyfungal_10000.dat")
compute_bdeu_scores("data/barleyfungal/barleyfungal_10000.dat","data/barleyfungal/barleyfungal_10000.jkl")


sample_datapoints_from_model("data/barleyfungal/barleyfungal.bif",50, "data/barleyfungal/barleyfungal_50.csv","data/barleyfungal/barleyfungal_50.dat")
compute_bdeu_scores("data/barleyfungal/barleyfungal_50.dat","data/barleyfungal/barleyfungal_50.jkl")

sample_datapoints_from_model("data/barleyfungal/barleyfungal.bif",200, "data/barleyfungal/barleyfungal_200.csv","data/barleyfungal/barleyfungal_200.dat")
compute_bdeu_scores("data/barleyfungal/barleyfungal_200.dat","data/barleyfungal/barleyfungal_200.jkl")
sample_datapoints_from_model("data/barleyfungal/barleyfungal.bif", 1000, "data/barleyfungal/barleyfungal_1000.csv","data/barleyfungal/barleyfungal_1000.dat")
compute_bdeu_scores("data/barleyfungal/barleyfungal_1000.dat","data/barleyfungal/barleyfungal_1000.jkl")# takes jkl file k not gıven all k gıven then a txt fıle to measure coverage fractıon saves logs in a log fıle the results 
#!/usr/bin/env python3

"""
experiment_heuristics_with_timeout.py

This script:
  1) Reads a Gobnilp .jkl file (local scores) and parses it into a sumu-compatible Scores object.
  2) Reads a text file of sampled DAGs to compute coverage fraction against.
  3) Optionally reads a dataset CSV if needed by certain sumu algorithms (like 'mb', 'pc', 'ges').
  4) Runs several candidate-parent heuristics from sumu (and a custom beam search example) 
     for K in [K_min..K_max].
  5) Computes coverage fraction and logs results to a CSV file and prints to stdout.
  6) Skips any heuristic call that exceeds --skip_after_seconds (default 300s = 5 min).

Usage:
  python experiment_heuristics_with_timeout.py \
      --jkl_file data/hailfinder_scores.jkl \
      --sampled_dags data/hailfinder_sampled_dags.txt \
      --data_file data/hailfinder_dataset.csv \
      --K_min 1 \
      --K_max 30 \
      --skip_after_seconds 300 \
      --output_csv coverage_log.csv


"""

import argparse
import time
import numpy as np
import pandas as pd
import os
import data_io
import heuristics
print(heuristics.__file__)
import coverage 

# sumu and related modules
import sumu
from sumu.candidates import candidate_parent_algorithm as cpa


#(base) gulce@gulce-HP-Laptop:~/Downloads/thesis$ python experiments/heuristic_performance_experiments.py     --jkl_file data/asia_scores.jkl     --sampled_dags data/asia_sampled.txt     --data_file data/asia_dataset.csv     --K_min 1     --K_max 7    --skip_after_seconds 300     --output_csv data/coverage/asia_coverage_results.csv
#
##############################################################################
# 6. main()
##############################################################################
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--jkl_file", type=str, required=True,
                        help="Path to the Gobnilp .jkl scores file.")
    parser.add_argument("--sampled_dags", type=str, required=True,
                        help="Path to the text file containing sampled DAGs.")
    parser.add_argument("--data_file", type=str, default=None,
                        help="Path to a CSV data file (optional), needed for certain sumu heuristics (mb, pc, ges, etc.).")
    parser.add_argument("--K_min", type=int, default=1,
                        help="Minimum K for candidate parents.")
    parser.add_argument("--K_max", type=int, default=10,
                        help="Maximum K for candidate parents.")
    parser.add_argument("--output_csv", type=str, default="coverage_log.csv",
                        help="Path to output CSV with coverage fraction results.")
    parser.add_argument("--sample_mode", type=str, default="exact modular",
                        help="exact sampling or mcmc")
    parser.add_argument("--skip_after_seconds", type=int, default=300,
                        help="Time limit (in seconds) for each heuristic call. If exceeded, skip.")
    args = parser.parse_args()

    # 1. Parse JKL -> GobnilpScores
    parsed_scores = data_io.parse_gobnilp_jkl(args.jkl_file)
    scores = heuristics.GobnilpScores(parsed_scores)
    n = scores.n

    # 2. Parse sampled DAGs
    sampled_dags = data_io.parse_dag_file(args.sampled_dags)

    # 3. Optionally load data for sumu algorithms that require the original data
    #    We'll also store the number of data rows in `num_data_rows`.
    mydata = None
    num_data_rows = 0
    if args.data_file and os.path.exists(args.data_file):
        # If the second row has e.g. arity or an extraneous row, adapt skiprows if needed:
        # df = pd.read_csv(args.data_file, skiprows=[1])
   
        df = pd.read_csv(args.data_file, skiprows=[1])

        mydata = sumu.Data(df.values)  
        num_data_rows = df.shape[0]
        print(f"[INFO] Loaded data file {args.data_file} with {num_data_rows} rows.")
    else:
        print("No data file given or file does not exist; 'mb', 'pc', 'ges' etc. might fail if used.")
    print(cpa.keys())
    # 4. Define the candidate algorithms we want to test
    candidate_algos = {
        "top":         (cpa["top"],         {"scores": scores, "n": n}),
         "opt":         (cpa["opt"],         {"scores": scores, "n": n}),
        #"mb":          (cpa["mb"],          {"data": mydata, "fill": "random"}),
         #"pc":          (cpa["pc"],          {"data": mydata, "fill": "random"}),
        #"ges":         (cpa["ges"],         {"scores": scores, "data": mydata, "fill": "top"}),
        "greedy":      (cpa["greedy"],      {"scores": scores}),
        "greedy-lite": (cpa["greedy-lite"], {"scores": scores}),
        "back-forth":  (cpa["back-forth"],  {"scores": scores, "data": scores.data}),
        "beam":        (heuristics.beam_bdeu,          {"scores": scores, "beam_size": 5}),
        #"marginal_bdeu_parents":        (heuristics.marginal_bdeu_parents,            {"scores": scores, "n": n}),
        
         "voting_bdeu_parents":        (heuristics.bdeu_score_based_voting,            {"scores": scores}),
         "synergy": (heuristics.synergy_based_parent_selection,  {"scores": scores}),
        "stability":(heuristics.stability_bdeu, {"scores": scores, "data": mydata}),
        "post":         (heuristics.maximize_true_graph_posterior,         {"scores": scores}),
        
        
        
        
        
    }

    # 5. Loop over each algorithm, vary K, measure coverage, respect time limit
    #    We'll now store the number of data rows in the results, too.
    results = []  # will store tuples of (algorithm, K, coverage_fraction, num_data_rows)

    for algo_name, (algo_func, algo_kwargs) in candidate_algos.items():
        print(f"\n*** Running algorithm: {algo_name} ***")
        for K in range(args.K_min, args.K_max + 1):
            print(f"   [K={K}] ...", end="", flush=True)
            start_time = time.time()
            candidate_parents = None

            # Attempt to run the heuristic
            try:
                tmp_result = algo_func(K, **algo_kwargs)
                # Some sumu CPAs return (C, None) or (C, extra).
                if isinstance(tmp_result, tuple) and len(tmp_result) >= 1:
                    candidate_parents = tmp_result[0]
                else:
                    candidate_parents = tmp_result
            except Exception as e:
                # Could be an error if data wasn't provided for 'mb' or 'pc', or other issues
                print(f"  [ERROR] {e}")
                results.append((algo_name, K, None, num_data_rows))
                continue

            # Check elapsed time
            elapsed = time.time() - start_time
            if elapsed > args.skip_after_seconds:
                # If it took more than skip_after_seconds, skip it
                print(f"  [SKIPPED: took {elapsed:.1f}s > {args.skip_after_seconds}s]")
                results.append((algo_name, K, None, num_data_rows,None))
                break

            # Otherwise, measure coverage
            cf = coverage.coverage_fraction(candidate_parents, sampled_dags)
            print(f"  coverage={cf}, time={elapsed:.1f}s")
            results.append((algo_name, K, cf, num_data_rows,candidate_parents))

    # 6. Save results to CSV
    df_res = pd.DataFrame(results, columns=["Algorithm", "K", "CoverageFraction", "NumDataRows",'CandidateParents'])
    df_res.to_csv(args.output_csv, index=False)
    print(f"\nCoverage results saved to: {args.output_csv}")
    if num_data_rows > 0:
        print(f"All coverage fractions above used dataset with {num_data_rows} rows.")
    else:
        print("No dataset was loaded (NumDataRows=0).")


if __name__ == "__main__":
    main()

# mybnexp/heuristics.py

import numpy as np
import logging

import sumu
from sumu.candidates import candidate_parent_algorithm as cpa
class Data:
    """Simple container for the number of variables `n`."""
    def __init__(self, n):
        self.n = n

class GobnilpScores:
    """
    A Scores-like class that wraps the output of parse_gobnilp_jkl 
    for use with sumu's candidate parent algorithms.
    """
    def __init__(self, parsed_scores):
        """
        Args:
            parsed_scores (dict): 
                A dict of { node: [ (score, (parents...)), ... ], ... }
        """
        self.n = max(parsed_scores.keys()) + 1
        self.data = Data(self.n)
        print("-----------------------------------",flush=True)
        
        # Store local scores in { node: {parents_tuple: score} }
        self.scores = {}
        for node, sp_list in parsed_scores.items():
            self.scores[node] = {}
            for (score, parents) in sp_list:
                parents_sorted = tuple(sorted(parents))
                self.scores[node][parents_sorted] = score

        # If you do not have a known maximum parent set size, keep this -1
        self.maxid = -1

    def local(self, v, parents):
        """
        Sumu calls 'scores.local(...)' in the candidate generation.
        So, we must provide this method name exactly.
        """
        p_sorted = tuple(sorted(parents))
        return self.scores[v].get(p_sorted, float("-inf"))
    
    
    def _local(self, v, parents):
        """
        Sumu calls 'scores.local(...)' in the candidate generation.
        So, we must provide this method name exactly.
        """
        p_sorted = tuple(sorted(parents))
        return self.scores[v].get(p_sorted, float("-inf"))

    def all_candidate_restricted_scores(self, C):
        import numpy as np
        print("-----------------------------------",flush=True)
        V = len(C)
        # Compute the number of subsets for each node.
        subset_counts = [1 << len(C[i]) for i in range(V)]
        max_subset_count = max(subset_counts)
        arr = np.full((V, max_subset_count), float("-inf"), dtype=float)
        
        for i in range(V):
            # Ensure the candidate parents for node i are sorted.
            sorted_parents = sorted(C[i])
            subset_count = 1 << len(sorted_parents)
            for m in range(subset_count):
                # Reverse the bit order so that the leftmost (first) element of the sorted list
                # corresponds to the most significant bit.
                parents_tuple = tuple(
                    sorted_parents[k] for k in range(len(sorted_parents))
                    if (m & (1 << (len(sorted_parents) - 1 - k)))
                )
                # Look up the score; if missing, use -inf.
                sc = self.scores[i].get(parents_tuple, float("-inf"))
                arr[i, m] = sc
        return arr


    def sum(self, v, U, T):

        from itertools import combinations

        # Compute the union of sets U and T
        combined_parents = U | T  # This will create a single set containing all elements from U and T

        # Determine the maximum number of parents (no limit in this case)
        max_parents = len(combined_parents)

        total_score = float("-inf")

        # Iterate over all possible parent sets from the union of U and T
        for k in range(max_parents + 1):
            for parent_set in combinations(combined_parents, k):
                score = self.local(v, parent_set)
                total_score = np.logaddexp(total_score, score)

        return total_score

    def clear_cache(self):
        """If your scoring logic uses caching, clear it here; otherwise do nothing."""
        pass
        """_summary_
        """    

    def filter_parent_sets_by_size(self, k):
            """
            Filter the local scores to only include candidate parent sets with exactly k parents.
            """
            for node in self.scores:
                self.scores[node] = {
                    parents: score
                    for parents, score in self.scores[node].items()
                    if len(parents) == k
                }


    def clear_cache(self):
        """If your scoring logic uses caching, clear it here; otherwise do nothing."""
        pass
    


def beam_bdeu(K, scores, beam_size=5, seed=None):
    """
    Custom beam search to pick exactly K parents for each node, maximizing local BDeu (scores.local).

    Returns: dict: node -> tuple_of_parents
    """
    if seed is not None:
        np.random.seed(seed)
    
    n = scores.n

    def score(v, pset):
        # sumu's scores.local expects a list or np.array
        return scores.local(v, np.array(list(pset)))

    candidate_parents = {}
    for v in range(n):
        # all possible parents except v
        possible_parents = [u for u in range(n) if u != v]

        if len(possible_parents) < K:
            logging.warning(f"Node {v}: cannot pick K={K} parents out of {len(possible_parents)} possible!")
            # fallback or raise an error
            raise ValueError(f"Node {v} has fewer than K possible parents.")

        # Start beam with empty set
        beam = [(score(v, []), frozenset())]

        for _ in range(K):
            new_level = []
            for (old_score, pset) in beam:
                for cand in possible_parents:
                    if cand not in pset:
                        new_pset = set(pset)
                        new_pset.add(cand)
                        new_score = score(v, new_pset)
                        new_level.append((new_score, frozenset(new_pset)))
            
            new_level.sort(key=lambda x: x[0], reverse=True)
            beam = new_level[:beam_size]
        
        # best among subsets of size K
        best_score, best_pars = max(beam, key=lambda x: x[0])
        candidate_parents[v] = tuple(sorted(best_pars))

    return candidate_parents


def get_candidate_parents(algo_name, K, scores, data=None, fill="top", **kwargs):
    """
    Return candidate parents for each node, depending on `algo_name`.

    If algo_name == "beam", uses custom beam_bdeu.
    Otherwise uses sumu's built-in candidate_parent_algorithm (cpa).

    Returns: dict: {node: parent_set or parent_tuple}
    """
    if algo_name == "beam":
        return beam_bdeu(K=K, scores=scores, **kwargs)
    else:
        # use sumu's cpa
        algo = cpa[algo_name]
        # Some cpa methods require data; some do not. We unify the call:
        # By default, let's pass both scores and data if they exist:
        return algo(K, scores=scores, data=data, fill=fill)


import numpy as np
from itertools import combinations
from math import log, exp

def logsumexp(x):
    """Stable log-sum-exp."""
    max_x = np.max(x)
    return max_x + np.log(np.sum(np.exp(x - max_x)))

def marginal_bdeu_parents(K, **kwargs):
    """
    Select candidate parents by marginal BDeu posterior.

    For each node v, we compute for each potential parent u:
        P(u in ParentSet(v)) = sum_{S : u in S} exp( BDeu(v,S) )
    normalized by the sum of exp( BDeu(v,S) ) over *all* S.

    Then pick top-K parents of v by this marginal probability.

    Parameters
    ----------
    K : int
        Maximum number of parents to keep for each node.
    kwargs : dict
        Must contain 'scores', which is a GobnilpScores-like object with:
            - scores.scores[v]: dict {parents_tuple: log_bdeu_score}
            - a 'local(v, parents)' method
            - an integer 'n' or 'scores.data.n' for the number of variables
        Optionally can contain 'n', if not inferred from the scores object.
        'fill' can be 'none', 'top', or 'random'.

    Returns
    -------
    C : dict
        Dictionary of the form { v : tuple_of_parents }.
    """
    # 1) Get scores object
    scores = kwargs.get("scores", None)
    if scores is None:
        raise ValueError("marginal_bdeu_parents requires 'scores' in kwargs.")
    
    fill_method = kwargs.get("fill", "none")

    # 2) Determine number of variables 'n'
    n = kwargs.get("n", None)
    if n is None:
        # Attempt to retrieve n from the scores object
        if hasattr(scores, "n"):
            n = scores.n
        elif hasattr(scores, "data") and hasattr(scores.data, "n"):
            n = scores.data.n
        else:
            raise ValueError("Cannot find 'n' from either kwargs or the scores object.")

    # 3) Dictionary to hold the final candidate parents
    C = {}

    # 4) Loop over each node v
    for v in range(n):

        # Instead of 'if v not in scores:', use 'scores.scores'
        if v not in scores.scores:
            # If no entry, means no known subsets => no candidates
            C[v] = ()
            continue

        # v_subsets: dict mapping { (p1, p2, ...): log_BDeu, ... }
        v_subsets = scores.scores[v]
        if not v_subsets:
            # empty => no parents
            C[v] = ()
            continue

        # -- Compute the log normalizer: logsumexp over all subsets' scores
        all_log_scores = list(v_subsets.values())
        normalizer = logsumexp(all_log_scores)  # log Z

        # -- For each potential parent u != v, gather log-scores of subsets that contain u
        logp_u = {}
        for u in range(n):
            if u == v:
                continue
            log_values = []
            for parent_set, logscore in v_subsets.items():
                if u in parent_set:
                    log_values.append(logscore)
            if len(log_values) == 0:
                logp_u[u] = float("-inf")  # u never appears in any subset
            else:
                logp_u[u] = logsumexp(log_values)

        # -- Sort parents by logp_u[u] descending (equivalent to marginal posterior)
        candidate_list = [(u, lv) for (u, lv) in logp_u.items()]
        candidate_list.sort(key=lambda x: x[1], reverse=True)

        # -- Pick top-K
        chosen = [u for (u, lv) in candidate_list[:K]]
        C[v] = tuple(sorted(chosen))

    # 5) If fill_method is 'top' or 'random', optionally fill/prune to K exactly
    if fill_method in ["top", "random"]:
        C = _adjust_number_candidates(K, C, method=fill_method, scores=scores)

    return C


def _adjust_number_candidates(K, C, method, scores=None):
    """Adjust the number of candidate parents to exactly K for each node."""
    assert method in ['random', 'top'], "method must be 'random' or 'top'"
    
    for v in C:
        current_parents = list(C[v])
        parent_count = len(current_parents)

        if parent_count < K:
            # Need to ADD parents
            needed = K - parent_count
            add_from = [node for node in range(len(C)) if node != v and node not in current_parents]

            if method == 'random':
                chosen = np.random.choice(add_from, needed, replace=False)
                current_parents += chosen.tolist()

            elif method == 'top' and scores is not None:
                scored_list = []
                for parent_candidate in add_from:
                    score_val = scores.local(v, np.array([parent_candidate]))
                    scored_list.append((parent_candidate, score_val))
                scored_list.sort(key=lambda x: x[1], reverse=True)
                best = [p for (p, s_val) in scored_list[:needed]]
                current_parents += best

        elif parent_count > K:
            # Need to PRUNE parents
            excess = parent_count - K
            if method == 'random':
                chosen_to_keep = np.random.choice(current_parents, K, replace=False)
                current_parents = list(chosen_to_keep)
            elif method == 'top' and scores is not None:
                scored_list = []
                for p in current_parents:
                    score_val = scores.local(v, np.array([p]))
                    scored_list.append((p, score_val))
                scored_list.sort(key=lambda x: x[1], reverse=True)
                current_parents = [p for (p, s_val) in scored_list[:K]]

        # Update
        C[v] = tuple(sorted(set(current_parents)))

    return C
import numpy as np
from itertools import combinations

def score_improvement(v, u, scores, potential_parents):
    """
    Calculate the score improvement for adding a parent u to the current parent set of node v.
    
    Parameters:
    v: Node for which we are selecting parents.
    u: Potential parent to be added.
    scores: GobnilpScores-like object containing the BDeu scores.
    potential_parents: Current set of parents for node v.
    
    Returns:
    score_improvement: The improvement in the BDeu score when adding parent u.
    """
    # Get the current score of the node v with its current parent set
    current_score = scores.local(v, np.array(potential_parents))
    
    # Add the potential parent u to the current set of parents
    new_parents = tuple(sorted(potential_parents + (u,)))
    new_score = scores.local(v, np.array(new_parents))
    
    # The improvement in the BDeu score is the difference
    score_improvement = new_score - current_score
    return score_improvement

import numpy as np
import logging

import sumu
from sumu.candidates import candidate_parent_algorithm as cpa


########################################
# 1) Fix the Data class so "object of type 'Data' has no len()" is resolved:
########################################
class Data:
    """Simple container for the number of variables `n`."""
    def __init__(self, n):
        self.n = n

    def __len__(self):
        """
        Some code (like stability selection) tries to do `len(data)`.
        Defining this lets that code run without TypeError.
        But be aware that if code tries `data[idx, :]`, 
        you still need __getitem__ for real row-based sampling.
        """
        return self.n
    
    def __len__(self):
        """
        If needed, let's define __len__ so that code 
        that calls len(data) won't crash. 
        """
        return self.n


class GobnilpScores:
    """
    A Scores-like class that wraps the output of parse_gobnilp_jkl 
    for use with sumu's candidate parent algorithms.
    """
    def __init__(self, parsed_scores):
        """
        Args:
            parsed_scores (dict): 
                A dict of { node: [ (score, (parents...)), ... ], ... }
        """
        self.n = max(parsed_scores.keys()) + 1
        self.data = Data(self.n)
        
        # Store local scores in { node: {parents_tuple: score} }
        self.scores = {}
        for node, sp_list in parsed_scores.items():
            self.scores[node] = {}
            for (score, parents) in sp_list:
                parents_sorted = tuple(sorted(parents))
                self.scores[node][parents_sorted] = score

        # If you do not have a known maximum parent set size, keep this -1
        self.maxid = -1

    def local(self, v, parents):
        """
        Sumu calls 'scores.local(...)' in the candidate generation.
        So, we must provide this method name exactly.
        """
        p_sorted = tuple(sorted(parents))
        return self.scores[v].get(p_sorted, float("-inf"))
    
    def _local(self, v, parents):
        """
        Same as 'local' above; sometimes sumu calls _local(...) internally.
        """
        p_sorted = tuple(sorted(parents))
        return self.scores[v].get(p_sorted, float("-inf"))

    def all_candidate_restricted_scores(self, C):
        import numpy as np
        V = len(C)
        # Compute the number of subsets for each node.
        subset_counts = [1 << len(C[i]) for i in range(V)]
        max_subset_count = max(subset_counts)
        arr = np.full((V, max_subset_count), float("-inf"), dtype=float)
        
        for i in range(V):
            # Sort the candidate parents for node i.
            sorted_parents = sorted(C[i])
            subset_count = 1 << len(sorted_parents)
            for m in range(subset_count):
                # Use natural bit order: bit k corresponds to sorted_parents[k]
                parents_tuple = tuple(
                    sorted_parents[k]
                    for k in range(len(sorted_parents))
                    if (m & (1 << k))
                )
                # Look up the score; if missing, use -inf.
                sc = self.scores[i].get(parents_tuple, float("-inf"))
                arr[i, m] = sc
        return arr


    def sum(self, v, U, T):
        """
        Example method that sums log-scores over subsets from the union of U and T,
        for node v.
        """
        from itertools import combinations
        combined_parents = U | T
        max_parents = len(combined_parents)
        total_score = float("-inf")

        for k in range(max_parents + 1):
            for parent_set in combinations(combined_parents, k):
                score = self.local(v, parent_set)
                total_score = np.logaddexp(total_score, score)
        return total_score

    def clear_cache(self):
        """If your scoring logic uses caching, clear it here; otherwise do nothing."""
        pass


########################################
# 2) "beam_bdeu" is fine, no changes needed
########################################
def beam_bdeu(K, scores, beam_size=5, seed=None):
    if seed is not None:
        np.random.seed(seed)
    
    n = scores.n

    def score(v, pset):
        return scores.local(v, np.array(list(pset)))

    candidate_parents = {}
    for v in range(n):
        possible_parents = [u for u in range(n) if u != v]

        if len(possible_parents) < K:
            logging.warning(f"Node {v}: cannot pick K={K} parents out of {len(possible_parents)} possible!")
            raise ValueError(f"Node {v} has fewer than K possible parents.")

        beam = [(score(v, []), frozenset())]

        for _ in range(K):
            new_level = []
            for (old_score, pset) in beam:
                for cand in possible_parents:
                    if cand not in pset:
                        new_pset = set(pset)
                        new_pset.add(cand)
                        new_score = score(v, new_pset)
                        new_level.append((new_score, frozenset(new_pset)))
            
            new_level.sort(key=lambda x: x[0], reverse=True)
            beam = new_level[:beam_size]
        
        best_score, best_pars = max(beam, key=lambda x: x[0])
        candidate_parents[v] = tuple(sorted(best_pars))

    return candidate_parents


def get_candidate_parents(algo_name, K, scores, data=None, fill="top", **kwargs):
    """
    Return candidate parents for each node, depending on `algo_name`.
    If algo_name == "beam", uses custom beam_bdeu.
    Otherwise uses sumu's built-in candidate_parent_algorithm (cpa).
    """
    if algo_name == "beam":
        return beam_bdeu(K=K, scores=scores, **kwargs)
    else:
        # use sumu's cpa
        algo = cpa[algo_name]
        return algo(K, scores=scores, data=data, fill=fill, **kwargs)


########################################
# 3) Marginal BDeu - ensure no "list+tuple" issues or 'v not in scores' issues
########################################
from itertools import combinations
from math import log

def logsumexp(x):
    """Stable log-sum-exp."""
    max_x = np.max(x)
    return max_x + np.log(np.sum(np.exp(x - max_x)))


def marginal_bdeu_parents(K, **kwargs):
    scores = kwargs.get("scores", None)
    if scores is None:
        raise ValueError("marginal_bdeu_parents requires 'scores' in kwargs.")
    
    fill_method = kwargs.get("fill", "none")

    n = kwargs.get("n", None)
    if n is None:
        if hasattr(scores, "n"):
            n = scores.n
        elif hasattr(scores, "data") and hasattr(scores.data, "n"):
            n = scores.data.n
        else:
            raise ValueError("Cannot find 'n' in kwargs or scores object.")

    C = {}

    for v in range(n):
        if v not in scores.scores:
            C[v] = ()
            continue

        v_subsets = scores.scores[v]
        if not v_subsets:
            C[v] = ()
            continue

        all_log_scores = list(v_subsets.values())
        normalizer = logsumexp(all_log_scores)

        logp_u = {}
        for u in range(n):
            if u == v:
                continue
            log_values = []
            for parent_set, logscore in v_subsets.items():
                if u in parent_set:
                    log_values.append(logscore)
            if len(log_values) == 0:
                logp_u[u] = float("-inf")
            else:
                logp_u[u] = logsumexp(log_values) - normalizer

        # sort by logp_u[u] desc
        candidate_list = [(u, lv) for (u, lv) in logp_u.items()]
        candidate_list.sort(key=lambda x: x[1], reverse=True)

        chosen = [u for (u, lv) in candidate_list[:K]]
        C[v] = tuple(sorted(chosen))

    if fill_method in ["top", "random"]:
        C = _adjust_number_candidates(K, C, method=fill_method, scores=scores)

    return C


def _adjust_number_candidates(K, C, method, scores=None):
    assert method in ['random', 'top'], "method must be 'random' or 'top'"
    
    for v in C:
        current_parents = list(C[v])
        parent_count = len(current_parents)

        if parent_count < K:
            needed = K - parent_count
            add_from = [node for node in range(len(C)) if node != v and node not in current_parents]

            if method == 'random':
                chosen = np.random.choice(add_from, needed, replace=False)
                current_parents += chosen.tolist()

            elif method == 'top' and scores is not None:
                scored_list = []
                for parent_candidate in add_from:
                    score_val = scores.local(v, np.array([parent_candidate]))
                    scored_list.append((parent_candidate, score_val))
                scored_list.sort(key=lambda x: x[1], reverse=True)
                best = [p for (p, s_val) in scored_list[:needed]]
                current_parents += best

        elif parent_count > K:
            if method == 'random':
                chosen_to_keep = np.random.choice(current_parents, K, replace=False)
                current_parents = list(chosen_to_keep)
            elif method == 'top' and scores is not None:
                scored_list = []
                for p in current_parents:
                    score_val = scores.local(v, np.array([p]))
                    scored_list.append((p, score_val))
                scored_list.sort(key=lambda x: x[1], reverse=True)
                current_parents = [p for (p, s_val) in scored_list[:K]]

        C[v] = tuple(sorted(set(current_parents)))

    return C


########################################
# 4) BDeu Score-Based Voting (bdeu_score_based_voting) 
#    to handle "list+tuple" fixes
########################################
def score_improvement(v, u, scores, current_set):
    """
    Calculate the improvement from adding parent u to `current_set` for node v.
    """
    current_score = scores.local(v, np.array(current_set))
    new_parents = tuple(sorted(current_set + (u,)))
    new_score = scores.local(v, np.array(new_parents))
    return new_score - current_score

def bdeu_score_based_voting(K, **kwargs):
    scores = kwargs.get("scores", None)
    if scores is None:
        raise ValueError("bdeu_score_based_voting requires 'scores' in kwargs.")
    
    n = kwargs.get("n", None)
    if n is None:
        n = scores.n if hasattr(scores, "n") else scores.data.n
    
    C = {}

    for v in range(n):
        potential_parents = [u for u in range(n) if u != v]
        
        # For each parent, measure improvement
        parent_contributions = {}
        for u in potential_parents:
            # treat the "current_set" as empty for measure
            improvement = score_improvement(v, u, scores, ())
            parent_contributions[u] = improvement
        
        sorted_parents = sorted(parent_contributions, key=parent_contributions.get, reverse=True)
        C[v] = tuple(sorted(sorted_parents[:K]))
    
    return C


########################################
# 5) Synergy-based approach 
#    Accept 'n=None' so no "unexpected keyword argument 'n'" error
########################################
def synergy_for_node(
    v, K, scores, alpha=0.0, fallback=True
):
    """
    Select up to K parents for node v using synergy-based search.
    
    If no positive synergy is found, we stop. If that yields fewer
    than K parents and 'fallback' is True, we pick top singletons
    from the leftover candidates to fill up to K.
    
    v : int
        The node index
    K : int
        Maximum number of parents
    scores : GobnilpScores
        Has .local(v, parents) -> log BDeu
    alpha : float
        Synergy offset factor
    fallback : bool
        Whether to fallback to top singletons if synergy picks fewer than K.
    """
    n = scores.n
    candidates = [u for u in range(n) if u != v]

    # Precompute BDeu(empty) and singletons
    bdeu_empty = scores.local(v, np.array([], dtype=int))
    bdeu_single = {u: scores.local(v, np.array([u])) for u in candidates}

    S = ()  # current parent set
    while len(S) < K:
        best_gain = float("-inf")
        best_u = None

        # current BDeu of S
        bdeu_S = scores.local(v, np.array(S))

        for u in candidates:
            if u in S:
                continue
            # synergy gain = BDeu(S ∪ {u}) - BDeu(S) - alpha*(BDeu({u}) - BDeu({}))
            bdeu_Su = scores.local(v, np.array(S + (u,)))
            gain = bdeu_Su - bdeu_S
            if alpha > 0:
                gain -= alpha * (bdeu_single[u] - bdeu_empty)

            if gain > best_gain:
                best_gain = gain
                best_u = u

        if best_gain <= 0 or best_u is None:
            # no further synergy improvement
            break

        # Otherwise add best_u
        S = tuple(sorted(S + (best_u,)))

    # if synergy yields fewer than K parents and fallback==True,
    # optionally fill from best singletons among leftover candidates
    if fallback and len(S) < K:
        # leftover are the candidates not in S
        leftover = [u for u in candidates if u not in S]
        # sort by single-parent BDeu descending
        leftover.sort(key=lambda u: bdeu_single[u], reverse=True)
        needed = K - len(S)
        # pick top 'needed' leftover
        fill_pars = leftover[:needed]
        S = tuple(sorted(S + tuple(fill_pars)))

    return S


###############################################################################
# Synergy-based parent selection for all nodes
###############################################################################
def synergy_based_parent_selection(K, scores, alpha=0.0, fallback=True):
    """
    For each node v, call synergy_for_node(...) to pick up to K parents.
    
    K : int
        Max parents
    scores : GobnilpScores
        log BDeu data
    alpha : float
        synergy offset
    fallback : bool
        Whether to fill parents with best singletons if synergy picks none.
    """
    n = scores.n
    C = {}
    for v in range(n):
        # If the node has no local scores, we can't pick anything
        if v not in scores.scores or len(scores.scores[v]) == 0:
            C[v] = ()
            continue

        # Otherwise run synergy
        chosen = synergy_for_node(v, K, scores, alpha=alpha, fallback=fallback)
        C[v] = chosen

    return C


########################################
# 6) Example "stability_bdeu" approach
#    We define a minimal fix to allow len(data) by using Data.__len__ above.
########################################

def stability_bdeu(K, scores, data, B=20, threshold=0.5, fill='top'):
    """
    Perform bootstrap-based stability selection for candidate parents 
    using BDeu scores. If the BDeu scores are empty or all -inf, 
    we gracefully return empty sets or fallback.

    Parameters
    ----------
    K : int
        Max number of parents per node.
    scores : GobnilpScores
        BDeu scoring object for the full dataset.
    data : array-like or Data object
        The 'dataset'. If it is just Data(n), there's no real row dimension.
    B : int
        Number of bootstrap samples.
    threshold : float
        Frequency threshold in [0,1].
    fill : str
        'top' or 'random' or 'none', how to fill if fewer than K stable parents.

    Returns
    -------
    C_stable : dict
        { v : tuple_of_parents } with up to K parents.
    """
    n = scores.n
    # freq[v,u] = how many times u was chosen for v
    freq = np.zeros((n, n), dtype=float)

    for _ in range(B):
        # 1) "sample" data. If real data is not provided, 
        #    this simply returns 'data' or does nothing
        sampled_data = bootstrap_data(data)
        # 2) compute BDeu scores from the sampled data
        sampled_scores = scores

        # 3) pick top-K parents in *this bootstrap* for each node
        #    using our fallback-based function:
        C_b = pick_top_k_parents(sampled_scores, K)

        for v, parents in C_b.items():
            for p in parents:
                freq[v, p] += 1

    freq /= B  # convert to frequency

    # Now build stable sets
    C_stable = {}
    for v in range(n):
        stable_pars = [u for u in range(n) if u != v and freq[v, u] >= threshold]
        if len(stable_pars) > K:
            # prune
            stable_pars.sort(key=lambda u: freq[v,u], reverse=True)
            stable_pars = stable_pars[:K]
        elif len(stable_pars) < K and fill=='top':
            # fill
            others = [u for u in range(n) if u != v and u not in stable_pars]
            others.sort(key=lambda x: freq[v,x], reverse=True)
            needed = K - len(stable_pars)
            stable_pars += others[:needed]

        C_stable[v] = tuple(sorted(stable_pars))

    return C_stable

###############################################################################
# 2) Bootstrapping and BDeu scoring stubs with fallback
###############################################################################
def bootstrap_data(data):
    """
    If data is just Data(n), we do no real sampling. 
    For a real dataset, you would do e.g.:

    idxs = np.random.choice(len(data), len(data), replace=True)
    return data[idxs, :]
    """
    return data



###############################################################################
# 3) pick_top_k_parents with fallback to avoid empty sets
###############################################################################
def pick_top_k_parents(scores, K):
    """
    For each node v, pick top-K parents from scores.
    If the node has no singletons or all -inf, fallback to empty set.
    """
    C_b = {}
    n = scores.n

    for v in range(n):
        # If scores is missing or empty, fallback to ()
        if v not in scores.scores or not scores.scores[v]:
            C_b[v] = ()
            continue

        # Collect single-parent subsets
        singletons = {}
        for pset, val in scores.scores[v].items():
            if len(pset) == 1:
                singletons[pset[0]] = val

        # If singletons is empty, fallback to the best available set
        # For example, pick the highest scoring multi-parent if it exists:
        if not singletons:
            # fallback to the best subset overall
            best_sub = None
            best_val = float("-inf")
            for pset, val in scores.scores[v].items():
                if val > best_val:
                    best_val = val
                    best_sub = pset
            if best_sub is None or best_val == float("-inf"):
                # no valid subsets => empty
                C_b[v] = ()
            else:
                # If best_sub has more than K parents, we still prune
                if len(best_sub) <= K:
                    C_b[v] = tuple(sorted(best_sub))
                else:
                    # arbitrary prune if best_sub is bigger than K
                    # e.g. pick top K parents from best_sub
                    C_b[v] = tuple(sorted(best_sub)[:K])
            continue

        # Otherwise pick top K singletons
        sorted_singles = sorted(singletons.items(), key=lambda x: x[1], reverse=True)
        top_k = [p for (p, sc) in sorted_singles[:K]]
        C_b[v] = tuple(sorted(top_k))

    return C_b
import gurobipy as gp
from gurobipy import GRB
import itertools
import numpy as np


class BayesianNetwork:
    def __init__(self, structure, scores):
        """
        structure: dict of node -> tuple/set of parent nodes
        scores: GobnilpScores (with real BDeu up to 3 parents)
        """
        self.structure = structure
        self.scores = scores

    def compute_posterior(self):
        """
        Sums up real local scores.  If any node has more than 3 parents,
        the real GobnilpScores.local(...) might be -inf => -inf total.
        So this step is only valid if you do indeed have those bigger sets scored,
        or you rely on the same approximation again here.
        """
        total_score = 0.0
        for node, pars in self.structure.items():
            val = self.scores.local(node, tuple(sorted(pars)))
            if val == float('-inf'):
                return float('-inf')
            total_score += val
        return total_score

def approximate_score(node, parents, scores):
    """
    Approximate local score using existing up-to-3-parent data.
    If parents has size > 3, pick best 3-subset's real local score as a stand-in.
    """
    if len(parents) <= 3:
        return scores.local(node, tuple(sorted(parents)))

    best_sub_score = -float("inf")
    for sub in itertools.combinations(parents, 3):
        sc = scores.local(node, tuple(sorted(sub)))
        if sc > best_sub_score:
            best_sub_score = sc
    return best_sub_score

def compute_approx_score_for_candidate(node, parents, scores):
    """
    Use an approximate scheme to get a 'score' for sets possibly > 3 parents.
    """
    return approximate_local_score(node, parents, scores)

def approximate_local_score(node, parents, scores):
    """
    Approximate local score for sets with > 3 parents by averaging
    the real GobnilpScores for all 3-subsets.

    If len(parents) <= 3, just return the real local score.
    """
    from math import isfinite
    
    sz = len(parents)
    # If 3 or fewer, return the real score
    if sz <= 3:
        return scores.local(node, tuple(sorted(parents)))

    # For > 3, let's compute the average across all 3-subsets
    all_3_subsets = list(itertools.combinations(parents, 3))
    scores_3sub = []
    for sub in all_3_subsets:
        sc_sub = scores.local(node, tuple(sorted(sub)))
        if isfinite(sc_sub):
            scores_3sub.append(sc_sub)
        else:
            # If any 3-subset is -inf, we can either skip it or treat it as -inf
            # (which will drag the average down heavily).
            scores_3sub.append(float('-inf'))

    if not scores_3sub:
        # If they are all -inf, the approximate score is -inf
        return float('-inf')
    
    # Return the average or the max or any combination
    return sum(scores_3sub)/len(scores_3sub)


def maximize_true_graph_posterior( K,scores):
    """
    Column generation for exactly K parents per node,
    but if K>3, we approximate the local score of a bigger set by
    the best 3-parent subset (or another scheme).

    Returns: a dict of node -> chosen parent set (size exactly K).
    """
    n=scores.n
    master = gp.Model("MasterProblem")
    master.Params.OutputFlag = 0

    x_vars = {}
    columns = {}

    # 1) Build candidate columns for each node: all subsets of size K
    for i in range(n):
        columns[i] = []
        possible_parents = [p for p in range(n) if p != i]

        for cand in itertools.combinations(possible_parents, K):
            sc = compute_approx_score_for_candidate(i, cand, scores)
            if np.isfinite(sc):
                var = master.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=1,
                                    name=f"x_{i}_{cand}")
                x_vars[(i, cand)] = var
                columns[i].append(cand)

    master.update()

    # 2) Constraints: each node picks exactly one K-parent set
    constrs = {}
    for i in range(n):
        if len(columns[i]) == 0:
            raise ValueError(
                f"No feasible K={K} parent sets for node {i} with the approximate scoring."
            )
        constrs[i] = master.addConstr(
            gp.quicksum(x_vars[(i, c)] for c in columns[i]) == 1,
            name=f"node_{i}"
        )
    master.update()

    # 3) Objective: sum of approximate scores
    obj_expr = gp.LinExpr()
    for i in range(n):
        for cand in columns[i]:
            sc = compute_approx_score_for_candidate(i, cand, scores)
            obj_expr.addTerms(sc, x_vars[(i, cand)])
    master.setObjective(obj_expr, GRB.MAXIMIZE)
    master.update()

    # 4) Column generation loop
    improved = True
    iteration = 0
    while improved:
        iteration += 1
        master.optimize()
        if master.status != GRB.OPTIMAL:
            print(f"Master problem not optimal at iteration {iteration}; stopping.")
            break

        duals = {i: constrs[i].Pi for i in range(n)}
        improved = False

        # Pricing: find columns (K-subsets) with positive reduced cost
        for i in range(n):
            best_rc = -float('inf')
            best_cand = None
            possible_parents = [p for p in range(n) if p != i]
            for cand in itertools.combinations(possible_parents, K):
                if cand in columns[i]:
                    continue
                sc = compute_approx_score_for_candidate(i, cand, scores)
                if not np.isfinite(sc):
                    continue
                rc = sc - duals[i]
                if rc > best_rc:
                    best_rc = rc
                    best_cand = cand

            # Add any new column with significantly positive reduced cost
            if best_cand is not None and best_rc > 1e-8:
                improved = True
                columns[i].append(best_cand)
                var = master.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=1,
                                    name=f"x_{i}_{best_cand}")
                x_vars[(i, best_cand)] = var
                master.chgCoeff(constrs[i], var, 1.0)
                master.setObjective(master.getObjective() + best_rc * var)
                master.update()

    # 5) Extract solution
    solution = {}
    for i in range(n):
        best_val = -1.0
        best_cand = None
        for cand in columns[i]:
            val = x_vars[(i, cand)].X
            if val > best_val:
                best_val = val
                best_cand = cand
        solution[i] = tuple(sorted(best_cand)) if best_cand else ()
        
    print(f"Column generation done after {iteration} iteration(s).")
    return solution
# import numpy as np
# from itertools import combinations
# from scipy.optimize import linprog

# # --- Dummy parser and classes for demonstration purposes ---

# import data_io
# import heuristics
# # --- ILP with Cutting Planes ---
# class ILPwithCuttingPlanes:
#     def __init__(self, scores):
#         self.scores = scores
#         self.n_nodes = scores.n
#         self.local_scores = scores.local_scores

#     def formulate_ilp(self):
#         """
#         Formulate the ILP by creating an objective vector (c) and
#         equality constraints (A_eq and b_eq) so that exactly one candidate
#         parent set is selected per node.
#         """
#         n = self.n_nodes
#         c = []
#         for node in range(n):
#             # Extend c with the score for each candidate parent set for this node
#             c.extend(self.local_scores[node].values())
#         # Each node must have exactly one selected parent set.
#         A_eq = np.zeros((n, len(c)))
#         b_eq = np.ones(n)
#         idx = 0
#         for node in range(n):
#             for parent_set in self.local_scores[node].keys():
#                 A_eq[node, idx] = 1
#                 idx += 1
#         return c, A_eq, b_eq

#     def solve_ilp(self, c, A_eq, b_eq):
#         """
#         Solve the ILP using scipy's linprog.
#         (Note: This performs a linear relaxation; in practice you might
#         want to use a dedicated MILP solver such as Gurobi or CPLEX.)
#         """
#         result = linprog(c=-np.array(c), A_eq=A_eq, b_eq=b_eq,
#                          bounds=[(0, 1)] * len(c), method='highs')
#         if result.success:
#             return result.x
#         else:
#             return None

#     def add_cutting_plane(self, A_eq, b_eq, violated_constraint):
#         """
#         Add a cutting plane constraint.
#         violated_constraint should be a tuple (new_row, rhs).
#         """
#         new_constraint = violated_constraint
#         A_eq = np.vstack([A_eq, new_constraint[0]])
#         b_eq = np.append(b_eq, new_constraint[1])
#         return A_eq, b_eq

#     def check_violated_constraints(self, solution):
#         """
#         Placeholder for checking if any domain-specific constraints are violated.
#         Implement logic here to detect violations based on your criteria.
#         For this example, we assume no violations.
#         """
#         return None

#     def solve_with_cutting_planes(self, max_iter=10):
#         """
#         Solve the ILP, iteratively adding cutting planes if any constraint
#         is violated.
#         """
#         c, A_eq, b_eq = self.formulate_ilp()
#         solution = self.solve_ilp(c, A_eq, b_eq)
#         if solution is None:
#             print("Initial ILP solution failed")
#             return None
#         for _ in range(max_iter):
#             violated_constraint = self.check_violated_constraints(solution)
#             if violated_constraint:
#                 A_eq, b_eq = self.add_cutting_plane(A_eq, b_eq, violated_constraint)
#                 solution = self.solve_ilp(c, A_eq, b_eq)
#                 if solution is None:
#                     print("ILP solution failed after cutting plane addition")
#                     return None
#             else:
#                 return solution
#         return solution

# def interpret_solution(solution, scores):
#     """
#     Convert the flattened solution vector back into a configuration
#     mapping each node to its selected candidate parent set.
#     """
#     parent_set_config = []
#     idx = 0
#     for node in range(scores.n):
#         num_candidates = len(scores.local_scores[node])
#         for i in range(num_candidates):
#             if solution[idx + i] == 1:
#                 # Retrieve the candidate parent set (by order of keys)
#                 candidate = list(scores.local_scores[node].keys())[i]
#                 parent_set_config.append((node, candidate))
#         idx += num_candidates
#     return parent_set_config

# def filter_parent_sets_by_size(scores, k):
#     for node in scores.local_scores:
#         scores.local_scores[node] = {
#             parents: score
#             for parents, score in scores.local_scores[node].items()
#             if len(parents) == k
#         }

# # --- Main Execution ---
# if __name__ == '__main__':
#     # Replace with your actual parser if available:
#     parsed_scores = data_io.parse_gobnilp_jkl('/home/gulce/Downloads/thesis/data/asia/asia_scores.jkl')
#     scores = heuristics.GobnilpScores(parsed_scores)
    
#     # Restrict candidate parent sets to exactly k parents.
#     k = 2 # Change k to the desired number of parents.

    
#     print("Filtered local_scores (only parent sets of size {}):".format(k))
#     for node, candidates in scores.local_scores.items():
#         print("Node {}: {}".format(node, candidates))
    
#     # Create and solve the ILP with cutting planes.
#     ilp_solver = ILPwithCuttingPlanes(scores)
#     best_solution = ilp_solver.solve_with_cutting_planes()
    
#     if best_solution is not None:
#         print("\nBest parent set configuration (solution vector):")
#         print(best_solution)
#         config = interpret_solution(best_solution, scores)
#         print("\nInterpreted configuration:")
#         for node, parents in config:
#             print(f"Node {node} selected parent set: {parents}")
#     else:
#         print("No feasible solution found.")
import gurobipy as gp
from gurobipy import GRB
import itertools
import numpy as np

class BayesianNetwork:
    def __init__(self, structure, scores):
        """
        structure: dict of node -> tuple/set of parent nodes
        scores: GobnilpScores (with real BDeu up to 3 parents)
        """
        self.structure = structure
        self.scores = scores

    def compute_posterior(self):
        """
        Sums up real local scores.  If any node has more than 3 parents,
        the real GobnilpScores.local(...) might be -inf => -inf total.
        So this step is only valid if you do indeed have those bigger sets scored,
        or you rely on the same approximation again here.
        """
        total_score = 0.0
        for node, pars in self.structure.items():
            val = self.scores.local(node, tuple(sorted(pars)))
            if val == float('-inf'):
                return float('-inf')
            total_score += val
        return total_score

def approximate_local_score(node, parents, local_scores):
    """
    Approximate local score using existing up-to-3-parent data.
    If parents has size > 3, pick best 3-subset's real local score as a stand-in.
    """
    if len(parents) <= 3:
        return local_scores.local(node, tuple(sorted(parents)))

    best_sub_score = -float("inf")
    for sub in itertools.combinations(parents, 3):
        sc = local_scores.local(node, tuple(sorted(sub)))
        if sc > best_sub_score:
            best_sub_score = sc
    return best_sub_score

def maximize_true_graph_posterior(local_scores, n, K):
    """
    Column generation for exactly K parents per node,
    but if K>3, we approximate the local score of a bigger set by
    the best 3-parent subset (or another scheme).

    Returns: a dict of node -> chosen parent set (size exactly K).
    """
    master = gp.Model("MasterProblem")
    master.Params.OutputFlag = 0

    x_vars = {}
    columns = {}

    # Step 1: build candidate columns of size K
    for i in range(n):
        columns[i] = []
        possible_parents = [p for p in range(n) if p != i]

        # All combinations of size K
        for cand in itertools.combinations(possible_parents, K):
            sc = approximate_local_score(i, cand, local_scores)
            # If the approximate score is not -inf or NaN, keep it
            if np.isfinite(sc):
                var = master.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=1,
                                    name=f"x_{i}_{cand}")
                x_vars[(i, cand)] = var
                columns[i].append(cand)

    master.update()

    # Step 2: constraints
    constrs = {}
    for i in range(n):
        if not columns[i]:
            raise ValueError(f"No feasible K={K} parent sets (even approximate) for node {i}.")
        constrs[i] = master.addConstr(
            gp.quicksum(x_vars[(i, c)] for c in columns[i]) == 1,
            name=f"node_{i}"
        )
    master.update()

    # Step 3: objective
    obj_expr = gp.LinExpr()
    for i in range(n):
        for cand in columns[i]:
            sc = approximate_local_score(i, cand, local_scores)
            obj_expr.addTerms(sc, x_vars[(i, cand)])
    master.setObjective(obj_expr, GRB.MAXIMIZE)
    master.update()

    # Step 4: Column generation loop
    improved = True
    iteration = 0
    while improved:
        iteration += 1
        master.optimize()
        if master.status != GRB.OPTIMAL:
            print(f"Master not solved to optimality at iteration {iteration}. Stopping.")
            break

        # Dual values
        duals = {i: constrs[i].Pi for i in range(n)}
        improved = False

        # Pricing
        for i in range(n):
            best_rc = -float('inf')
            best_cand = None
            for cand in itertools.combinations([p for p in range(n) if p != i], K):
                if cand in columns[i]:
                    continue
                sc = approximate_local_score(i, cand, local_scores)
                if not np.isfinite(sc):
                    continue
                rc = sc - duals[i]
                if rc > best_rc:
                    best_rc = rc
                    best_cand = cand

            if best_cand is not None and best_rc > 1e-8:
                improved = True
                columns[i].append(best_cand)
                var = master.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=1,
                                    name=f"x_{i}_{best_cand}")
                x_vars[(i, best_cand)] = var
                master.chgCoeff(constrs[i], var, 1.0)
                # We can add (sc) * var or directly (rc) * var + duals[i]*var, etc.
                # But simpler is to just do sc * var:
                master.setObjective(master.getObjective() + rc * var)
                master.update()

    # Step 5: Extract solution
    solution = {}
    for i in range(n):
        best_val = -1
        best_cand = None
        for cand in columns[i]:
            val = x_vars[(i, cand)].X
            if val > best_val:
                best_val = val
                best_cand = cand
        solution[i] = tuple(sorted(best_cand)) if best_cand else ()

    print(f"Done. Column generation took {iteration} iteration(s).")
    return solution


# --------------------
# Example usage (pseudo code; adapt paths and modules as needed)

if __name__ == "__main__":
    import data_io
    import heuristics
    import heuristics_variable_data_experiments as var

    # Parse scores from your Gobnilp .jkl file
    parsed_scores = data_io.parse_gobnilp_jkl('/home/gulce/Downloads/thesis/data/sachs/sachs_scores.jkl')
    scores = heuristics.GobnilpScores(parsed_scores)

    # Solve for some K > 3, e.g. K=4
    K = 4
    solution = maximize_true_graph_posterior(scores, scores.n, K)
    print("Solution:", solution)

    # Evaluate posterior of the found network
    bn = BayesianNetwork(solution, scores)
    posterior = bn.compute_posterior()
    print("Log Posterior of Found Network:", posterior)

    # Compare to the 'true' or reference network
    true_parents = var.get_true_parents('/home/gulce/Downloads/thesis/data/sachs/sachs.bif')
    bn_true = BayesianNetwork(true_parents, scores)
    print("True Parents:", true_parents)
    posterior_true = bn_true.compute_posterior()
    print("Log Posterior of Reference Network:", posterior_true)

    bn = BayesianNetwork({0: (2, 3), 1: (0, 2), 2: (0, 1), 3: (0, 2), 4: (2, 5), 5: (2, 3), 6: (2, 3), 7: (2, 5), 8: (9, 10), 9: (8, 10), 10: (8, 9)}, scores)
  
    posterior = bn.compute_posterior()
    print("Log of the Posterior Probability of the opT Network:", posterior)

import subprocess
def sample_from_exact_modular_sampler(jkl_file,n,output_file):

    # Define the command as a list of arguments
    command = ["/home/gulce/Downloads/thesis/modular-dag-sampling-master/sampler", "nonsymmetric", jkl_file, n]

    # Specify the output file
    

    # Run the command and write its output to the file
    with open(output_file, "w") as file:
        with open('/home/gulce/Downloads/thesis/data/child/error.log', 'w') as err_file:
            try:
                result = subprocess.run(command, check=True, text=True, stdout=file, stderr=err_file)
                print("Command executed successfully! Output written to", output_file)
            except subprocess.CalledProcessError as e:
                print("An error occurred while executing the command.")
                print("Error message:", e.stderr)
                
                
# sample_from_exact_modular_sampler("/home/gulce/Downloads/thesis/data/asia/barleyfungal_500.jkl","100000","/home/gulce/Downloads/thesis/data/asia/asia_500.txt")
sample_from_exact_modular_sampler("/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_10000.jkl","100000","/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_10000.txt")           
sample_from_exact_modular_sampler("/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_1000.jkl","100000","/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_1000.txt")   
sample_from_exact_modular_sampler("/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_200.jkl","100000","/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_200.txt")              
sample_from_exact_modular_sampler("/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_50.jkl","100000","/home/gulce/Downloads/thesis/data/barleyfungal/barleyfungal_50.txt") 
   


def sample_from_exact_modular_fair_sampler(n,k,m,output_file):

    # Define the command as a list of arguments
    command = ["/home/gulce/Downloads/thesis/modular-dag-sampling-master/sampler", "symmetric",'fair',  str(n),str(k), str(m)]

    # Specify the output file
    

    # Run the command and write its output to the file
    with open(output_file, "w") as file:
        with open('/home/gulce/Downloads/thesis/data/barleyfungal/error.log', 'w') as err_file:
            try:
                result = subprocess.run(command, check=True, text=True, stdout=file, stderr=err_file)
                print("Command executed successfully! Output written to", output_file)
            except subprocess.CalledProcessError as e:
                print("An error occurred while executing the command.")
                print("Error message:", e.stderr)


            
    
import heuristics
import data_io
def mcmc_sample_pymc(jkl_file,n,output_file):
    scores=data_io.parse_gobnilp_jkl(jkl_file)
    parsed_scores=heuristics.GobnilpScores(scores)
    import logging
    import numpy as np
    import pymc as pm

# Setup logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

        
    import pymc as pm
    import numpy as np

    def build_model(scores_obj, num_nodes):
        with pm.Model() as model:
            parent_choices = {}

            # Use `scores_obj.local_scores` instead of iterating over `scores_obj`
            for node in range(num_nodes):
                if node in scores_obj.scores:
                    node_scores = scores_obj.scores[node]  # Extract dictionary for node
                    
                    jittered_probs = []
                    
                    for parents, score in node_scores.items():  # Iterate over (parent_set, score)
                        jittered_score = score #+ np.random.normal(0, 0.01)  # Adding jitter
                        jittered_probs.append(jittered_score)

                    # Normalize jittered scores to sum to 1
                    jittered_probs = np.clip(jittered_probs, 0, 1)  # Ensure within [0,1]
                    total_prob = np.sum(jittered_probs)
                    
                    if total_prob == 0:
                        jittered_probs = np.ones_like(jittered_probs) / len(jittered_probs)  # Use uniform
                    else:
                        jittered_probs /= total_prob  # Normalize

                    # Define categorical distribution
                    parent_choices[node] = pm.Categorical(f'parents_of_{node}', p=jittered_probs, shape=(1,))

        return model


    # Building the model with the possibility of random starts
    model = build_model(parsed_scores, num_nodes=parsed_scores.n)


    with model:
        # Using different step methods and increasing tune and sample sizes
        step = pm.Metropolis()  # Using Metropolis for potentially better exploration
        trace = pm.sample(n, tune=1000000, step=step, return_inferencedata=False)




        # Extract sampled parent sets for analysis
        

    # Extract sampled parent sets for analysis
    sampled_parent_sets = {varname: trace.get_values(varname) for varname in model.named_vars}

    def decode_samples(sampled_parent_sets, scores):
        decoded_samples = set()  # Using a set to avoid duplicates

        for sample in range(len(sampled_parent_sets[list(sampled_parent_sets.keys())[0]])):
            dag = {}

            for node, choices in sampled_parent_sets.items():
                node_index = int(node.split('_')[-1])
                parent_index = choices[sample][0]  # Extract index from trace

                # Fix: Access `local_scores` properly
                try:
                    parents_dict = scores.scores[node_index]  # Get all parent sets for this node
                    parent_sets = list(parents_dict.keys())  # Get all parent sets as list
                    parents = parent_sets[parent_index]  # Select parent set by index
                except (KeyError, IndexError):
                    print(f"Warning: Invalid access for node {node_index} at index {parent_index}")
                    parents = ()

                dag[node_index] = frozenset(parents)

            decoded_samples.add(frozenset((k, frozenset(v)) for k, v in dag.items()))

        return decoded_samples


    decoded_dags = decode_samples(sampled_parent_sets, parsed_scores)



    def write_dags_to_file(dags, filename):
        with open(filename, 'w') as file:
            for dag_frozenset in dags:
                dag = {k: set(v) for k, v in dag_frozenset}
                dag_str = ', '.join(f"{node} <- {{{', '.join(map(str, sorted(parents)))}}}" 
                                    for node, parents in sorted(dag.items()))
                file.write(dag_str + "\n")

    write_dags_to_file(decoded_dags,output_file)
    def write_dags_to_file(dags, filename):
        with open(filename, 'w') as file:
            for dag_frozenset in dags:
                dag = {k: set(v) for k, v in dag_frozenset}
                dag_str = ', '.join(f"{node} <- {{{', '.join(map(str, sorted(parents)))}}}" 
                                    for node, parents in sorted(dag.items()))
                file.write(dag_str + "\n")

    write_dags_to_file(decoded_dags,output_file)
#mcmc_sample_pymc('/home/gulce/Downloads/thesis/data/credit/credit_10000.jkl',1000,'/home/gulce/Downloads/thesis/data/credit/credit_pymc_sampled_dags.txt')
# mcmc_sample_pymc('/home/gulce/Downloads/thesis/data/insurance/insurance_scores.jkl',1000000,'/home/gulce/Downloads/thesis/data/insurance/insurance_pymc_sampled_dags.txt')


# mcmc_sample_pymc('/home/gulce/Downloads/thesis/data/child/child_scores.jkl',10000,'/home/gulce/Downloads/thesis/data/child/child_pymc_sampled_dags.txt')
#mcmc_sample_pymc('/home/gulce/Downloads/thesis/data/hailfinder/hailfinder_scores.jkl',10000,'/home/gulce/Downloads/thesis/data/hailfinder/hailfinder_pymc_sampled_dags_clean.txt')












def sample_from_naive_mcmc_sampler(jkl_file,burn_in,txt_file,n):
    # Define the command and arguments as a list
    cmd = [
        "Rscript",
        "/home/gulce/Downloads/thesis/mcmc_sampler.r",
        jkl_file,
        burn_in,
        txt_file,
        n
    ]

    # Run the command
    result = subprocess.run(cmd, capture_output=True, text=True)

    # Print the standard output and error (if any)
    print("Standard Output:")
    print(result.stdout)
    print("Standard Error:")
    print(result.stderr)
import data_io
import heuristics

# parsed_scores = data_io.parse_gobnilp_jkl('/home/gulce/Downloads/thesis/data/sachs/sachs_rounded_10000_tempered.jkl')
# scores = heuristics.GobnilpScores(parsed_scores)
# print(scores.scores[0])

# import sumu
# from sumu.candidates import candidate_parent_algorithm as cpa
# cpa.keys()

# opt=cpa["opt"]
# opt_parents=opt(7, scores=scores,n= scores.n)
# print("1 million datapoint" ,opt_parents)

# parsed_scores = data_io.parse_gobnilp_jkl('/home/gulce/Downloads/thesis/data/sachs/sachs_500.jkl')
# scores = heuristics.GobnilpScores(parsed_scores)
# print(scores.scores[0])

# import sumu
# from sumu.candidates import candidate_parent_algorithm as cpa
# cpa.keys()

# opt=cpa["opt"]
# opt_parents_500=opt(3, scores=scores,n= scores.n)
# print("500 data point" ,opt_parents_500)
# import coverage 
# parents=coverage.get_true_parents("data/sachs/sachs_rounded.bif")
# print(parents)
# import data_io
# parsed_dags=data_io.parse_dag_file("/home/gulce/Downloads/thesis/temp_10000.txt")

# cov=coverage.coverage_fraction(parsed_dags[0],parsed_dags)
# print("cov ->", cov)

# opt=cpa["top"]
# opt_parents=opt(7, scores=scores,n= scores.n)
# print("1 million datapoint" ,opt_parents)

import sys
import re


import math
from decimal import Decimal, getcontext
import decimal




# def auto_tempered_gobnilp(input_file, output_file, target_max_diff=Decimal('-500'), precision=6):
#     with open(input_file, 'r') as fin:
#         original_lines = fin.readlines()

#     idx = 0
#     num_nodes = int(original_lines[idx].strip())
#     idx += 1

#     all_log_scores = []
#     positions = []  # Track the exact positions to replace scores later

#     # Read original scores and positions
#     for _ in range(num_nodes):
#         while idx < len(original_lines) and original_lines[idx].strip() == "":
#             idx += 1  # Skip empty lines

#         node_info = original_lines[idx].strip().split()
#         node_name, num_parent_sets = node_info[0], int(node_info[1])
#         idx += 1

#         parent_sets = []
#         for _ in range(num_parent_sets):
#             while idx < len(original_lines) and original_lines[idx].strip() == "":
#                 idx += 1  # Skip empty lines inside parent sets

#             line_parts = original_lines[idx].strip().split()
#             score = Decimal(line_parts[0])
#             parent_sets.append(score)
#             all_log_scores.append(score)
#             positions.append(idx)  # Remember the exact line to replace
#             idx += 1

#     # Automatic temperature selection
#     max_score, min_score = max(all_log_scores), min(all_log_scores)
#     max_diff = min_score - max_score
#     if max_diff == 0:
#         temperature = Decimal('1')
#     else:
#         temperature = max_diff / target_max_diff
#         if temperature < 1:
#             temperature = Decimal('1')

#     print(f"Automatically chosen temperature: {temperature}")

#     # Tempered normalization
#     tempered_scores = [lw / temperature for lw in all_log_scores]
#     max_tempered = max(tempered_scores)

#     sum_exp = sum(
#         (score - max_tempered).exp()
#         for score in tempered_scores
#         if (score - max_tempered) > Decimal('-700')
#     )
#     log_partition = max_tempered + sum_exp.ln()

#     # Final normalized and formatted scores
#     normalized_scores = [
#         f"{(score - log_partition):.{precision}f}" for score in tempered_scores
#     ]

#     # Write back the original file, replacing scores EXACTLY where they appeared
#     with open(output_file, 'w') as fout:
#         norm_idx = 0
#         for i, line in enumerate(original_lines):
#             if i in positions:
#                 parts = line.strip().split()
#                 # Replace only the score, keep the rest exactly as-is
#                 replaced_line = f"{normalized_scores[norm_idx]} {' '.join(parts[1:])}\n"
#                 fout.write(replaced_line)
#                 norm_idx += 1
#             else:
#                 fout.write(line)  # keep the line exactly as original


# # Example usage clearly and practically demonstrated:
# auto_tempered_gobnilp(
#     '/home/gulce/Downloads/thesis/data/sachs/sachs.jkl',
#     '/home/gulce/Downloads/thesis/data/sachs/sachs_tempered.jkl',
#     precision=6  # practical and recommended precision
# )







def arcs_coverage(dag_ref, candidate_parents):
    """
    Compute the fraction of arcs in 'dag_ref' that are 'guessed' by 'candidate_parents'.
    For each arc p->c in dag_ref, we check if 'p' appears in at least one candidate set
    for node 'c'.
    
    Returns a float in [0, 1]. If dag_ref has no arcs, we define coverage = 1.0
    (no arcs => trivially covered).
    """
    # Collect all arcs from the reference DAG
    # dag_ref is { child : [ list_of_parents ] }
    arcs = []
    for child, parents in dag_ref.items():
        for p in parents:
            arcs.append((p, child))
    total_arcs = len(arcs)
    
    # If there are no arcs at all, define coverage to be 1.0 (instead of 0.0)
    if total_arcs == 0:
        return 1.0

    guessed = 0
    for (p, c) in arcs:
        csets = candidate_parents.get(c, None)
        if csets is None:
            # No candidate sets for this child => can't guess any arcs
            continue
        
        # Normalize to a list of sets/tuples so we can iterate
        if isinstance(csets, (int, tuple, set)):
            csets = [csets]

        # If 'p' appears in at least one candidate set for child 'c', we count it as guessed
        is_guessed = False
        for cset in csets:
            if isinstance(cset, int):
                cset = {cset}
            else:
                cset = set(cset)
            if p in cset:
                is_guessed = True 
                break
        
        if is_guessed:
            guessed += 1
    
    return guessed / total_arcs
dag_ref = {
    0: [],
    1: [],    # 0->1
    2: [],    # 0->2
    3: [],  # 0->3, 2->3
    4: [],  # 1->4, 3->4
}
# So arcs are (0->1), (0->2), (0->3), (2->3), (1->4), (3->4).
# total arcs = 6

candidate_parents = {
    0: [1],
    1: [(0,),(1,)],
    2: [(0,),(1,)],
    3: [(0,), (2,)],  # We guess 0->3 in the first set, 2->3 in the second set
    4: [(1,), (3,)], 
    # That means 1->4 is guessed (by set (1,)), 
    # and 3->4 is guessed (by set (3,)).
    # But we do NOT have (2,) for node 4 => wait, we do have (2,) but that 
    # doesn't guess 1->4 or 3->4. Actually we do have (1,) or (3,). That’s enough.
}

cov=arcs_coverage(dag_ref, candidate_parents)

print(cov)
# import two_phase_global_coverage
# # r=two_phase_global_coverage.find_best_dag_referencer(5, 2)
# # print(r)
# from collections import Counter

# def check_parent_set_sizes(dags):
#     size_counter = Counter()
#     for dag in dags:
#         for parents in dag.values():
#             size_counter[len(parents)] += 1
#     return size_counter

# parsed = data_io.parse_dag_file("/home/gulce/Downloads/thesis/data/sachs/sachs_1000.txt")
# size_dist = check_parent_set_sizes(parsed)
# print(size_dist)

# from collections import defaultdict, Counter
    
# def most_frequent_parent_sets_k(dags, k):
#     """
#     For a list of DAGs (each DAG is {node: set_of_parents}), and an integer k,
#     determine for each node which parent set(s) of size k appear most often
#     across all DAGs.

#     Returns:
#       A dict: {node: [list_of_frozensets]}.
#     """
#     node_parent_counter = defaultdict(Counter)
    
#     # We first collect the set of all possible nodes, if not provided
#     if all_nodes is None:
#         all_nodes = set()
#         for dag in dags:
#             all_nodes.update(dag.keys())

#     for dag in dags:
#         for node, parents in dag.items():
#             if len(parents) == k:
#                 node_parent_counter[node][frozenset(parents)] += 1

#     node_most_frequent = {}
#     for node in all_nodes:  # loop over every node
#         parent_set_counts = node_parent_counter[node]  # a Counter()
#         if not parent_set_counts:
#             # no sets of size k for this node
#             node_most_frequent[node] = []
#         else:
#             max_count = max(parent_set_counts.values())
#             top_sets = [
#                 pset for pset, freq in parent_set_counts.items() if freq == max_count
#             ]
#             node_most_frequent[node] = top_sets

#     return node_most_frequent

# import data_io

# keep=most_frequent_parent_sets_k(parsed,3)
# print(keep)


import pandas as pd
import logging

def compute_mean_coverage(csv_path):
    """
    Reads the CSV file, groups by ['method', 'K'], 
    and computes mean coverage for coverage_prior and coverage_gobnilp.
    """
    # Read the data
    df_out = pd.read_csv(csv_path)
    
    # Group by method and K, then compute mean
    df_mean = df_out.groupby(["method", "K"], as_index=False)[
        ["coverage_prior"]
    ].mean()
    
    # Log the result
    logging.info("\nMean coverage across replicates:\n%s", df_mean)
    
    return df_mean

if __name__ == "__main__":
    # Set logging level to INFO so we can see the output in terminal
    logging.basicConfig(level=logging.INFO)

    # Update this path to the location of your CSV
    csv_file_path = "/home/gulce/Downloads/thesis/data/fair/coverage_log_nVars=10_maxInDeg=4_alpha=1.0_smallData=5000_refData=50000.csv"
    
    df_mean_coverage = compute_mean_coverage(csv_file_path)
    
    # Print or do something else with df_mean_coverage
    print(df_mean_coverage)
import pandas as pd
import logging

def debug_k9_coverage(csv_path):
    """
    Loads the CSV into a DataFrame, prints out all rows where K=9,
    and shows min, max, and mean coverage.
    """
    # Read the data
    df_out = pd.read_csv(csv_path)

    # Filter rows where K=9
    df_k9 = df_out[df_out["K"] == 9].copy()

    # If you expect coverage=1, see if it’s actually less than 1 in some rows
    # For coverage_prior and coverage_gobnilp, print out relevant info
    print("Rows where K=9:")
    print(df_k9[["method", "K", "coverage_prior", "coverage_gobnilp"]])

    # Show statistics for coverage_prior and coverage_gobnilp
    print("\nCoverage statistics at K=9:")
    print(df_k9[["coverage_prior", "coverage_gobnilp"]].describe())

    # Group by method as well, if that helps
    print("\nCoverage at K=9 grouped by method:")
    print(df_k9.groupby("method")[["coverage_prior", "coverage_gobnilp"]].agg(["mean", "min", "max"]))

if __name__ == "__main__":
    # Set up logging
    logging.basicConfig(level=logging.INFO)
    
    csv_file_path = "/home/gulce/Downloads/thesis/data/fair/coverage_log_nVars=10_maxInDeg=4_alpha=1.0_smallData=5000_refData=50000.csv"
    debug_k9_coverage(csv_file_path)
import pandas as pd

# Change this path to your actual CSV file
csv_file_path = "/home/gulce/Downloads/thesis/data/fair/coverage_log_nVars=10_maxInDeg=4_alpha=1.0_smallData=5000_refData=50000.csv"

df_out = pd.read_csv(csv_file_path)

# Find rows where K=9 and coverage_prior is not 1
df_k9_not_full = df_out.loc[(df_out["K"] == 9) & (df_out["coverage_prior"] < 1)]

# Print them out
print("Rows where K=9 but coverage_prior < 1:\n")
print(df_k9_not_full)

# If you also want to check coverage_gobnilp:
df_k9_not_full_gobnilp = df_out.loc[(df_out["K"] == 9) & (df_out["coverage_gobnilp"] < 1)]
print("\nRows where K=9 but coverage_gobnilp < 1:\n")
print(df_k9_not_full_gobnilp)#!/usr/bin/env python3

"""
two_phase_nodelevel_coverage.py (Debug Version)

Implements a 2-phase approach to measure coverage *node-by-node*:

  For each replicate r in 1..M:
    1) Sample (G*, cpts*) from a 'fair' prior
    2) Generate a small phantom dataset => pass to heuristic => for each node, returns candidate parent sets
    3) Generate a large reference dataset => run Gobnilp solver => obtains best DAG_ref
    4) coverage_r = 1 if for EVERY node i, the DAG_ref[i] is in heuristic's sets[i], else 0

At the end, we average coverage_r to get the final coverage fraction.
"""

import argparse
import numpy as np
import pandas as pd
import os
import random
import logging

# Set logging to DEBUG to ensure debug messages are shown
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')


def save_data(df,csv_file, dat_file):
    columns = [str(i) for i in range(len(df.columns))]
    print(columns)
    
    data = [[2] *( len(columns)+0)]
    # Convert to DataFrame
    df_arity = pd.DataFrame(data, columns=columns)

    column_mapping = {old: new for old, new in zip(df.columns, df_arity.columns)}
    df = df.rename(columns=column_mapping)

    # Now, combine the data as before
    df_combined_correct = pd.concat([df_arity, df], ignore_index=True)
    df_combined_correct.to_csv(csv_file, index=False)


    # Combine the arity information (first row) with the rest of the dataset
    df_combined_correct = pd.concat([df_arity, df])
    # Save the DataFrame to a CSV file for inspection or future use
    #df_arity.to_csv("data/original_hailfinder_dataset.csv", index=False)
    # Append the arity row (df_arity) on top of the data_samples
    df_combined = pd.concat([df_arity, df], ignore_index=True)

    # Save the combined dataset to a CSV file
    df_combined.to_csv(dat_file, index=False, sep=' ')    
    

##########################
# (A) "Fair" BN Prior
##########################
def sample_dag_fair_prior(n_vars, max_in_degree):
    """
    Sample exactly one random DAG on n_vars nodes
    from a 'fair' prior, ensuring no node has in-degree
    exceeding max_in_degree.
    """
    import sampling
    import data_io

    tmp_file = f"_tmp_dag_{random.randint(0,999999)}.txt"
    logging.debug(f"[sample_dag_fair_prior] About to sample DAG; writing to {tmp_file}")

    # sample 1 DAG
    n_dags_to_sample = 1
    sampling.sample_from_exact_modular_fair_sampler(
        n_vars, max_in_degree, n_dags_to_sample, tmp_file
    )

    dag_list = data_io.parse_dag_file(tmp_file)
    logging.debug(f"[sample_dag_fair_prior] Parsed {len(dag_list)} DAG(s) from {tmp_file}")

    # Cleanup
    if os.path.exists(tmp_file):
        os.remove(tmp_file)
    if not dag_list or len(dag_list) == 0:
        raise ValueError("No DAG was sampled from the fair prior.")
    dag = dag_list[0]
    logging.debug(f"[sample_dag_fair_prior] Final DAG: {dag}")

    return dag


def sample_cpts_for_dag(dag, alpha=1.0, num_states=2):
    """
    Sample random CPTs for each node given its parents,
    using a Dirichlet( alpha ) prior for each configuration.
    """
    import numpy as np
    cpts = {}
    for node, parents in dag.items():
        k = len(parents)
        n_config = num_states ** k
        table = np.zeros((n_config, num_states))
        for cfg in range(n_config):
            theta = np.random.gamma(alpha, size=num_states)
            theta /= theta.sum()
            table[cfg, :] = theta
        cpts[node] = table

    logging.debug("[sample_cpts_for_dag] Sampled CPTs for each node.")
    return cpts

def get_topological_order(dag):
    """
    Return a valid topological ordering of the nodes in 'dag'.
    dag = { child : [ list_of_parents ] }.
    """
    d = len(dag)
    in_deg = {n: 0 for n in dag}
    for child, pars in dag.items():
        for p in pars:
            in_deg[child] += 1

    queue = [x for x in in_deg if in_deg[x] == 0]
    order = []
    while queue:
        cur = queue.pop()
        order.append(cur)
        for child, ps in dag.items():
            if cur in ps:
                in_deg[child] -= 1
                if in_deg[child] == 0:
                    queue.append(child)

    if len(order) < d:
        raise ValueError("[get_topological_order] Graph is not a DAG or has a cycle.")

    logging.debug(f"[get_topological_order] Topological order = {order}")
    return order

def generate_data_from_dag(dag, cpts, sample_size, num_states=2):
    """
    Generate synthetic data from 'dag' and 'cpts',
    returning a numpy array of shape (sample_size, len(dag)).
    """
    import numpy as np
    d = len(dag)
    data = np.zeros((sample_size, d), dtype=int)
    topo = get_topological_order(dag)
    for s in range(sample_size):
        row = [None] * d
        for node in topo:
            par = dag[node]
            idx = 0
            for p in sorted(par):
                idx = idx * num_states + row[p]
            pvals = cpts[node][idx, :]
            val = np.random.choice(num_states, p=pvals)
            row[node] = val
        data[s, :] = row

    logging.debug(f"[generate_data_from_dag] Generated data of shape {data.shape} for sample_size={sample_size}.")
    return data
def get_sumu_scores_for_small_data(data_small, replicate_idx=0):
    """
    Generate local BDeu .jkl file for data_small, parse it with sumu.
    Return a sumu.scores object we can reuse for multiple heuristics.
    """
    import pandas as pd
    import data_preparation
    import data_io
    import heuristics
    prefix = f"smalldata_rep{replicate_idx}"
    csv_file = f"{prefix}.csv"
    dat_file = f"{prefix}.dat"
    jkl_file = f"{prefix}.jkl"

    df_small = pd.DataFrame(data_small)
    df_small.to_csv(csv_file, index=False)
    data_preparation.save_data(df_small, csv_file, dat_file)
    data_preparation.compute_bdeu_scores(dat_file, jkl_file)

    parsed_scores = data_io.parse_gobnilp_jkl(jkl_file)

    scores = heuristics.GobnilpScores(parsed_scores)  # or sumu_heur.GobnilpScores

    for f in [csv_file, dat_file, jkl_file]:
        if os.path.exists(f):
            os.remove(f)

    return scores

##########################
# (B) Heuristic on small data
##########################
def run_heuristic_on_small_data(data_small, replicate_idx=0):
    """
    We'll produce node->list_of_parent_sets for each node
    by using sumu with "greedy" (K=n).
    Then we won't unify them into a single DAG,
    but store them as candidate_parents[node] = [that single set or sets].
    """
    import pandas as pd
    import data_preparation
    import data_io
    import heuristics
    import sumu
    from sumu.candidates import candidate_parent_algorithm as cpa

    prefix = f"smalldata_rep{replicate_idx}"
    csv_file = f"{prefix}.csv"
    dat_file = f"{prefix}.dat"
    jkl_file = f"{prefix}.jkl"

    # Save data -> CSV -> DAT -> JKL
    df_small = pd.DataFrame(data_small)
    df_small.to_csv(csv_file, index=False)
    data_preparation.save_data(df_small, csv_file, dat_file)
    data_preparation.compute_bdeu_scores(dat_file, jkl_file)

    # Parse the JKL => wrap in GobnilpScores => pass to sumu greedy
    parsed_scores = data_io.parse_gobnilp_jkl(jkl_file)
    scores = heuristics.GobnilpScores(parsed_scores)
    n = scores.n
    logging.debug(f"[run_heuristic_on_small_data] JKL parsed -> scores for n={n} nodes")

    algo_func = cpa["greedy"]
    algo_kwargs = {"scores": scores}
    # Some code had 'algo_func(n-1, **algo_kwargs)', others used 'n'. Adjust as needed.
    tmp_result = algo_func(n-4, **algo_kwargs)

    if isinstance(tmp_result, tuple):
        candidate_parents = tmp_result[0]
    else:
        candidate_parents = tmp_result

    logging.debug(f"[run_heuristic_on_small_data] Candidate parents for each node: {candidate_parents}")

    # Cleanup
    for f in [csv_file, dat_file, jkl_file]:
        if os.path.exists(f):
            os.remove(f)

    return candidate_parents

##########################
# (C) ILP solver on large data => best DAG
##########################
def find_best_dag_reference(data_ref, replicate_idx=0):
    """
    Use rungobnilp.py on local BDeu scores from data_ref
    to get the single best DAG in .dot form, then parse.
    """
    import pandas as pd
    import data_preparation
    import data_io
    import heuristics
    prefix = f"refdata_rep{replicate_idx}"
    csv_file = f"{prefix}.csv"
    dat_file = f"{prefix}.dat"
    jkl_file = f"{prefix}.jkl"

    df_ref = pd.DataFrame(data_ref)
    df_ref.to_csv(csv_file, index=False)
    data_preparation.save_data(df_ref, csv_file, dat_file)
    data_preparation.compute_bdeu_scores(dat_file, jkl_file)

    logging.debug(f"[find_best_dag_reference] Created data/scores for replicate={replicate_idx}, now running rungobnilp.")
    run_gobnilp_for_best_dag(jkl_file, prefix)

    dot_file = f"{prefix}_gobnilp_solution.dot"
    dag_best = parse_best_dag_dot(dot_file)
    logging.debug(f"[find_best_dag_reference] Parsed DAG from {dot_file}: {dag_best}")

    # Cleanup
    for f in [csv_file, dat_file, jkl_file, dot_file]:
        if os.path.exists(f):
            os.remove(f)

    return dag_best


def run_gobnilp_for_best_dag(jkl_file, prefix):
    """
    Calls rungobnilp.py in 'scores' mode to find a best BN,
    producing a .dot file with the result.
    """
    import subprocess
    cmd = [
        "python3",
        "/home/gulce/Downloads/thesis/pygobnilp-1.0/rungobnilp.py",
        jkl_file,        # treat as local scores
        "--scores",
        "--nsols=1",
        "--nopruning",
        f"--output_stem={prefix}_gobnilp_solution",
        "--output_ext=dot",
        "--nooutput_cpdag",
        "--noabbrev",
        "--noplot"
    ]
    logging.info("[run_gobnilp_for_best_dag] Command: %s", " ".join(cmd))

    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        logging.error("[run_gobnilp_for_best_dag] Gobnilp call failed with return code %s", e.returncode)
        raise
import pydot
def parse_best_dag_dot(dot_file):
    """
    Parse adjacency from .dot => returns {node: [parents]}.
    If the file is missing or no edges, returns an empty dict.
    """
    dag_out = {}
    if not os.path.exists(dot_file):
        logging.warning(f"[parse_best_dag_dot] Solution .dot not found: {dot_file}")
        return dag_out

    # pydot can return a list of graphs if the .dot file has multiple subgraphs
    graphs = pydot.graph_from_dot_file(dot_file)
    if not graphs:
        logging.warning(f"[parse_best_dag_dot] No graphs found in {dot_file}.")
        return dag_out
    
    graph = graphs[0]  # assume the first graph is the main one

    # Get all edges in the graph
    for edge in graph.get_edges():
        src = edge.get_source()      # e.g. '8'
        dst = edge.get_destination() # e.g. '0'
        try:
            parent = int(src)
            child = int(dst)
        except ValueError:
            logging.warning(f"[parse_best_dag_dot] Non-integer node labels: {src} -> {dst}. Skipping.")
            continue

        if child not in dag_out:
            dag_out[child] = []
        dag_out[child].append(parent)

    # Ensure every node (0..max_node) is in the dictionary
    all_nodes = set()
    for c, ps in dag_out.items():
        all_nodes.add(c)
        all_nodes.update(ps)

    if all_nodes:
        max_node = max(all_nodes)
        for n in range(max_node + 1):
            if n not in dag_out:
                dag_out[n] = []

    return dag_out

##########################
# (D) Node-level coverage
##########################
def dag_nodes_covered(dag_ref, candidate_parents):
    """
    Check if DAG 'dag_ref' is "covered" by the candidate parents in 'candidate_parents'.
    For each node i, we require that the true parents of i are a *subset* of
    at least one candidate set. That is, Pa_G(X_i) ⊆ C_i for at least one C_i in candidate_parents[i].

    Parameters
    ----------
    dag_ref : dict
        Dictionary: node -> list_of_parents (the reference DAG).
    candidate_parents : dict
        Dictionary: node -> candidate set(s). Each entry can be:
          * a single tuple/list of parents
          * multiple tuples/lists (e.g., a list of possible parents sets)
          * None if no candidates found

    Returns
    -------
    bool
        True if for every node, there is at least one candidate set that contains all of its true parents.
        False otherwise.
    """
    print("COMPARE  : ",dag_ref,"--",candidate_parents)
    for node, ref_pa_list in dag_ref.items():
        ref_set = set(ref_pa_list)

        # Get the candidate sets for this node
        csets = candidate_parents.get(node, None)
        if csets is None:
            # No candidate parents => automatically fails coverage
            return False

        # Convert single tuples/ints to a list of sets for uniformity
        if isinstance(csets, tuple):
            csets = [csets]
        elif isinstance(csets, int):
            csets = [[csets]]

        # Now csets should be an iterable of candidate sets (each a tuple or list).
        # We only need ONE candidate set that covers ref_set (i.e. ref_set ⊆ cset).
        covered_this_node = False
        for cset in csets:
            cset_as_set = set(cset)
            if ref_set.issubset(cset_as_set):
                covered_this_node = True
                break

        if not covered_this_node:
            # If we never found a candidate set that contains all parents, coverage fails
            return False

    # If we never returned False, that means every node had at least one superset candidate set
    return True


def arcs_coverage(dag_ref, candidate_parents):
    """
    Compute the fraction of arcs in 'dag_ref' that are 'guessed' by 'candidate_parents'.
    For each arc p->c in dag_ref, we check if 'p' appears in at least one candidate set
    for node 'c'.
    
    Returns a float in [0, 1], or 0.0 if dag_ref has no arcs.
    """
    # Collect all arcs from the reference DAG
    # dag_ref is { child : [ list_of_parents ] }
    arcs = []
    for child, parents in dag_ref.items():
        for p in parents:
            arcs.append((p, child))
    total_arcs = len(arcs)
    if total_arcs == 0:
        return 1.0  # or define it as 1.0 if you prefer (no arcs => trivially covered)

    guessed = 0
    for (p, c) in arcs:
        csets = candidate_parents.get(c, None)
        if csets is None:
            # No candidate sets for this child => can't guess any arcs
            continue
        
        # Normalize to a list of sets/tuples so we can iterate
        if isinstance(csets, (int, tuple, set)):
            csets = [csets]

        # If 'p' appears in at least one candidate set for child 'c', we count it guessed
        is_guessed = False
        for cset in csets:
            # If a candidate set is just an int/tuple, turn it into a set
            if isinstance(cset, int):
                cset = {cset}
            else:
                cset = set(cset)
            if p in cset:
                is_guessed = True
                break
        
        if is_guessed:
            guessed += 1
    
    return guessed / total_arcs

from sumu.candidates import candidate_parent_algorithm as cpa
##########################
# (E) main
##########################
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--n_vars", type=int, default=10, help="Number of nodes (variables)")
    parser.add_argument("--max_in_degree", type=int, default=3, help="Max in-degree for the DAG prior")
    parser.add_argument("--num_states", type=int, default=2, help="Number of discrete states for each variable")
    parser.add_argument("--alpha", type=float, default=1.0, help="Dirichlet prior hyperparameter")
    parser.add_argument("--M", type=int, default=5, help="Number of replicates.")
    parser.add_argument("--small_data_size", type=int, default=500)
    parser.add_argument("--ref_data_size", type=int, default=10000)
    parser.add_argument("--output_csv", type=str, default="two_phase_nodelevel_coverage.csv")
    args = parser.parse_args()
    logging.debug(f"[main] Starting with arguments: {args}")

    # Build a string summarizing the key parameters (for filenames)
    param_str = (
        f"nVars={args.n_vars}_maxInDeg={args.max_in_degree}_"
        f"alpha={args.alpha}_smallData={args.small_data_size}_refData={args.ref_data_size}"
    )

    # Output CSV and log file with embedded parameters
    coverage_csv = f"coverage_{param_str}.csv"
    means_csv    = f"coverage_means_{param_str}.csv"
    log_file     = f"coverage_log_{param_str}.log"

    coverage_rows = []
    with open(log_file, "w") as lf:
        lf.write(f"# Detailed coverage log\n")
        lf.write(f"# Parameters: {param_str}\n\n")

        for r in range(args.M):
            logging.info(f"=== Replicate {r+1}/{args.M} ===")

            # 1) Sample G*, cpts*
            G_star = sample_dag_fair_prior(args.n_vars, args.max_in_degree)
            cpts_star = sample_cpts_for_dag(G_star, alpha=args.alpha, num_states=args.num_states)
            logging.debug(f"[main] Rep={r}, Sampled DAG (G_star) = {G_star}")

            # 2) Generate small data => compute scores
            data_small = generate_data_from_dag(G_star, cpts_star, args.small_data_size, args.num_states)
            scores_small = get_sumu_scores_for_small_data(data_small, replicate_idx=r)
            n = scores_small.n

            # (We might also prepare sumu.Data or do other pre-processing for the heuristics)
            import sumu
            mydata_small = sumu.Data(data_small)

            # 3) Generate large data => run Gobnilp => best DAG (DAG_ref)
            data_ref = generate_data_from_dag(G_star, cpts_star, args.ref_data_size, args.num_states)
            DAG_ref = find_best_dag_reference(data_ref, replicate_idx=r)
            logging.debug(f"[main] Rep={r}, DAG_ref => {DAG_ref}")

            # 4) For each algorithm, compute coverage w.r.t. DAG_ref *and* w.r.t. G_star
            from sumu.candidates import candidate_parent_algorithm as cpa
            import heuristics  # your custom heuristics.py

            candidate_algos = {
                "opt":            (cpa["opt"],            {"scores": scores_small, "n": n}),
                "top":            (cpa["top"],            {"scores": scores_small, "n": n}),
                "mb":             (cpa["mb"],             {"data": mydata_small, "fill": "random"}),
                "pc":             (cpa["pc"],             {"data": mydata_small, "fill": "random"}),
                "ges":            (cpa["ges"],            {"scores": scores_small, "data": mydata_small, "fill": "top"}),
                "greedy":         (cpa["greedy"],         {"scores": scores_small}),
                "greedy-lite":    (cpa["greedy-lite"],    {"scores": scores_small}),
                "back-forth":     (cpa["back-forth"],     {"scores": scores_small, "data": scores_small.data}),
                "beam":           (heuristics.beam_bdeu,  {"scores": scores_small, "beam_size": 5}),
                "marginal_bdeu_parents": (heuristics.marginal_bdeu_parents, {"scores": scores_small, "n": n}),
                "voting_bdeu_parents":   (heuristics.bdeu_score_based_voting, {"scores": scores_small}),
                "synergy":        (heuristics.synergy_based_parent_selection, {"scores": scores_small}),
                "stability":      (heuristics.stability_bdeu, {"scores": scores_small, "data": mydata_small}),
                "post":           (heuristics.maximize_true_graph_posterior, {"scores": scores_small}),
            }

            for algo_name, (algo_func, algo_kwargs) in candidate_algos.items():
                # We'll vary K from 1..(n-1), or some range
                for K in range(1, n):
                    try:
                        tmp_res = algo_func(K, **algo_kwargs)
                        if isinstance(tmp_res, tuple):
                            candidate_pars = tmp_res[0]
                        else:
                            candidate_pars = tmp_res
                    except Exception as e:
                        logging.warning(f"[Rep={r}] algo={algo_name}, K={K} error: {e}")
                        # If it fails, store coverage=0
                        coverage_rows.append((r, algo_name, K, 0, 0))
                        continue

                    cov_star = arcs_coverage(G_star, candidate_pars)
                    cov_ref  = arcs_coverage(DAG_ref, candidate_pars)
                   
                    # We'll store both coverage values
                    coverage_rows.append((r, algo_name, K, cov_star, cov_ref))
                    
                    # === HERE is the new logging block ===
                    lf.write("\n--------------------------------------------------\n")
                    lf.write(f"Rep={r}, ALGORITHM={algo_name}, K={K}\n\n")
                    lf.write(f"Candidate parents by heuristic:\n{candidate_pars}\n\n")
                    lf.write(f"PRIOR parents (G_star):\n{G_star}\n\n")
                    lf.write(f"GOBNILP parents (DAG_ref):\n{DAG_ref}\n\n")
                    lf.write(f"Coverage with PRIOR = {cov_star}, Coverage with GOBNILP = {cov_ref}\n")
                    lf.write("--------------------------------------------------\n\n")

    # Convert to DataFrame and summarize
    df_out = pd.DataFrame(
        coverage_rows,
        columns=["replicate", "method", "K", "coverage_prior", "coverage_gobnilp"]
    )
    
    df_out.to_csv(args.output_csv, index=False)
    logging.info(f"Saved raw results to {args.output_csv}")

    # Show mean coverage across replicates
    df_mean = df_out.groupby(["method", "K"], as_index=False)[["coverage_prior", "coverage_gobnilp"]].mean()
    logging.info("\nMean coverage across replicates:\n%s", df_mean)
    
    # Write a second CSV that has the average coverage
    df_mean.to_csv(means_csv, index=False)
    logging.info(f"Saved coverage means to {means_csv}")


if __name__ == "__main__":
    main()
#!/usr/bin/env python3

import re
import sys
import pandas as pd


def parse_coverage_log(log_file_path):
    """
    Reads a coverage log that has lines of the form:
      Rep=X, ALGORITHM=foo, K=Y
      ...
      Coverage with PRIOR = a, Coverage with GOBNILP = b

    Returns a list of tuples: (replicate, algorithm, K, coverage_prior, coverage_gobnilp).
    """
    pattern_header = re.compile(r'^Rep=(\d+),\s+ALGORITHM=([^,]+),\s+K=(\d+)')
    pattern_cov    = re.compile(r'^Coverage with PRIOR\s*=\s*([\d.]+),\s*Coverage with GOBNILP\s*=\s*([\d.]+)')

    coverage_data = []

    # We'll keep track of the last (rep, algo, K) we found,
    # so that once we see the coverage line, we can store that row.
    current_rep = None
    current_algo = None
    current_k = None

    with open(log_file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            # Check if it’s the "Rep=X, ALGORITHM=Y, K=Z" line
            match_header = pattern_header.match(line)
            if match_header:
                current_rep = int(match_header.group(1))
                current_algo = match_header.group(2).strip()
                current_k = int(match_header.group(3))
                continue

            # Check if it’s the coverage line
            match_cov = pattern_cov.match(line)
            if match_cov:
                cov_prior_str = match_cov.group(1)
                cov_gob_str   = match_cov.group(2)
                # Convert coverage strings to floats
                coverage_prior   = float(cov_prior_str)
                coverage_gobnilp = float(cov_gob_str)

                # Save row only if we have current_rep/algo/K
                if current_rep is not None and current_algo is not None and current_k is not None:
                    coverage_data.append((
                        current_rep,
                        current_algo,
                        current_k,
                        coverage_prior,
                        coverage_gobnilp
                    ))

    return coverage_data


def main(log_file_path, output_raw_csv, output_means_csv):
    # Parse the log => list of (rep, algo, K, coverage_prior, coverage_gobnilp)
    rows = parse_coverage_log(log_file_path)

    # Convert to DataFrame
    df = pd.DataFrame(
        rows,
        columns=['replicate', 'method', 'K', 'coverage_prior', 'coverage_gobnilp']
    )

    # Write the “raw” coverage results
    df.to_csv(output_raw_csv, index=False)
    print(f"Wrote raw coverage data to {output_raw_csv} (rows={len(df)})")

    # Compute mean coverage across replicates, grouped by (method, K)
    df_mean = df.groupby(['method', 'K'], as_index=False)[['coverage_prior','coverage_gobnilp']].mean()

    # Write the coverage means
    df_mean.to_csv(output_means_csv, index=False)
    print(f"Wrote coverage means to {output_means_csv}")



if __name__ == "__main__":
    """
    Usage:
        ./coverage_parser.py <coverage_log_file> <raw_csv> <means_csv>
    Example:
        ./coverage_parser.py coverage_nVars=10_maxInDeg=3_alpha=1.0_smallData=500_refData=10000.log \
                             coverage_raw.csv coverage_means.csv
    """
    if len(sys.argv) != 4:
        print("Usage: ./coverage_parser.py <coverage_log_file> <raw_csv> <means_csv>")
        sys.exit(1)

    log_file = sys.argv[1]
    raw_csv  = sys.argv[2]
    mean_csv = sys.argv[3]
    main(log_file, raw_csv, mean_csv)
import sys
import os
import argparse
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --------------------------------------------------------------------------
# 1. Optional Filtering Helper: top_n_algorithms
# --------------------------------------------------------------------------
def top_n_algorithms(df, sort_metric="F1", k_val=9, n=5):
    if sort_metric not in df.columns:
        print(f"[WARNING] sort_metric='{sort_metric}' not in columns. Skipping top_n filtering.")
        return df

    df_k = df[df['K'] == k_val].copy()
    if df_k.empty:
        print(f"[WARNING] No rows found where K={k_val}. Skipping top_n filtering.")
        return df

    df_k.sort_values(by=sort_metric, ascending=False, inplace=True)
    top_algos = df_k['Algorithm'].head(n).unique()
    print(f"[INFO] top_{n} algos by '{sort_metric}' at K={k_val}:", top_algos)

    return df[df['Algorithm'].isin(top_algos)].copy()


# --------------------------------------------------------------------------
# 2. Plot Approach A: Line Plot
# --------------------------------------------------------------------------
def plot_line(df, metric="Average Parent Coverage", xcol="K", save=None):
    df_sorted = df.copy()
    try:
        df_sorted[xcol] = df_sorted[xcol].astype(float)
    except ValueError:
        pass

    df_sorted.sort_values(by=xcol, inplace=True)

    plt.figure(figsize=(10, 6))
    sns.lineplot(data=df_sorted, x=xcol, y=metric, hue="Algorithm", marker="o")
    plt.title(f"Line Plot: {metric} vs. {xcol}")
    plt.tight_layout()
    
    if save:
        plt.savefig(save.replace('.csv','_line.png'))
        print(f"Plot saved as {save}")
    else:
        plt.show()


# --------------------------------------------------------------------------
# 3. Plot Approach B: Grouped Bar Chart
# --------------------------------------------------------------------------
def plot_bar(df, metric="Average Parent Coverage", xcol="K", save=None):
    df_bar = df.copy()
    try:
        df_bar[xcol] = df_bar[xcol].astype(float)
    except ValueError:
        pass

    df_bar.sort_values(by=xcol, inplace=True)

    plt.figure(figsize=(10, 6))
    ax = sns.barplot(data=df_bar, x=xcol, y=metric, hue="Algorithm", ci=None, edgecolor="black", width=0.8)
    plt.title(f"Grouped Bar: {metric} by {xcol} and Algorithm")
    plt.xticks(rotation=45)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)
    plt.tight_layout()

    if save:
        plt.savefig(save.replace('.csv','_bar.png'))
        print(f"Plot saved as {save}")
    else:
        plt.show()


# --------------------------------------------------------------------------
# 4. Plot Approach C: Facet Subplots
# --------------------------------------------------------------------------
def plot_facet(df, metric="Average Parent Coverage", xcol="K", save=None):
    df_facet = df.copy()
    try:
        df_facet[xcol] = df_facet[xcol].astype(float)
    except ValueError:
        pass

    g = sns.FacetGrid(df_facet, col="Algorithm", col_wrap=4, sharey=False, height=3)
    g.map_dataframe(sns.lineplot, x=xcol, y=metric, marker="o")
    g.set_titles(col_template="{col_name}")
    g.fig.suptitle(f"{metric} vs. {xcol} by Algorithm", y=1.05)
    plt.tight_layout()

    if save:
        plt.savefig(save.replace('.csv','_facet.png'))
        print(f"Plot saved as {save}")
    else:
        plt.show()


# --------------------------------------------------------------------------
# 5. Plot Approach D: Heatmap
# --------------------------------------------------------------------------
def plot_heatmap(df, metric="Average Parent Coverage", xcol="K",
                 heatmap_figsize=(30,24), save=None):
    """
    Creates a pivot table (Algorithm vs. K) of <metric> and displays
    as a heatmap, with a default figure size of (30,24).
    """
    df_hm = df.copy()
    try:
        df_hm[xcol] = df_hm[xcol].astype(float)
    except ValueError:
        pass

    pivoted = df_hm.pivot_table(index="Algorithm", columns=xcol, values=metric, aggfunc="mean")
    # Sort columns by ascending K
    pivoted = pivoted.reindex(sorted(pivoted.columns), axis=1)

    plt.figure(figsize=heatmap_figsize)
    sns.heatmap(pivoted, annot=True, fmt=".4f", cmap="YlGnBu",   annot_kws={"fontsize": 14} )
    plt.title(f"Heatmap of {metric} by Algorithm vs. {xcol}")
    plt.ylabel("Algorithm")
    plt.xlabel(xcol)
    plt.tight_layout()

    if save:
        outpath = save.replace('.csv','_heatmap.png')
        plt.savefig(outpath)
        print(f"[INFO] Heatmap plot saved as {outpath}")
    else:
        plt.show()


# --------------------------------------------------------------------------
# 6. Main Script
# --------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(description="Advanced coverage visualization with multiple plot types.")
    parser.add_argument("csv_file", help="Path to the coverage log CSV.")
    parser.add_argument("--plot_type", choices=["line", "bar", "facet", "heatmap"], default="bar", help="Choose one of: line, bar, facet, heatmap.")
    parser.add_argument("--metric", default="Average Parent Coverage", help="Which column to plot on the y-axis.")
    parser.add_argument("--k_col", default="K", help="Which column is used for the x-axis (default: K).")
    parser.add_argument("--sort_metric", default=None, help="If given, we pick top_n algorithms by this metric at K=k_max.")
    parser.add_argument("--k_max", type=float, default=5, help="Which K to use when picking top_n. Must be numeric. If not set, skip top_n.")
    parser.add_argument("--top_n", type=int, default=0, help="If >0, filter to top_n algorithms by --sort_metric at --k_max.")
    parser.add_argument("--exclude_consensus", action="store_true", help="If set, remove rows where Algorithm contains 'Consensus Parents'.")
    parser.add_argument("--save", type=str, help="Path to save the plot (e.g., 'plot.png').")

    args = parser.parse_args()

    # Load CSV
    if not os.path.isfile(args.csv_file):
        print(f"[ERROR] CSV file not found: {args.csv_file}")
        sys.exit(1)

    df = pd.read_csv(args.csv_file)
    print(f"[INFO] Loaded {df.shape[0]} rows from {args.csv_file}")
    print(f"[INFO] Columns: {df.columns.tolist()}")

    # Optionally exclude lines with "Consensus Parents"
    if args.exclude_consensus:
        before_count = df.shape[0]
        df = df[~df["Algorithm"].str.contains("Consensus Parents", na=False)].copy()
        after_count = df.shape[0]
        print(f"[INFO] Excluded consensus lines. Rows from {before_count} to {after_count}.")

    # top_n filtering if requested
    df = top_n_algorithms(df, sort_metric=args.sort_metric, k_val=args.k_max, n=5)

   

    plot_line(df, metric=args.metric, xcol=args.k_col, save=args.csv_file)

    plot_bar(df, metric=args.metric, xcol=args.k_col, save=args.csv_file)

    plot_facet(df, metric=args.metric, xcol=args.k_col, save=args.csv_file)

    plot_heatmap(df, metric=args.metric, xcol=args.k_col, save=args.csv_file)


if __name__ == "__main__":
    main()
import os
import pandas as pd
import matplotlib.pyplot as plt

# Create an output directory (if it doesn't exist)
os.makedirs("plots", exist_ok=True)

# Paths to the CSV files by sample size
files = {
    # 50:   "/home/gulce/Downloads/thesis/data/coverage/survey/survey_coverage_results_50.csv",
    # 100:  "/home/gulce/Downloads/thesis/data/coverage/survey/survey_coverage_results_100.csv",
    200:  "/home/gulce/Downloads/thesis/data/coverage/survey/survey_coverage_results_200.csv",
    1000:  "/home/gulce/Downloads/thesis/data/coverage/survey/survey_coverage_results_1000.csv",
    10000: "/home/gulce/Downloads/thesis/data/coverage/survey/survey_coverage_results_10000.csv"
}

# Read each file into a dictionary keyed by sample size
data_by_size = {}
for sample_size, path in files.items():
    data_by_size[sample_size] = pd.read_csv(path)

# Collect all unique algorithm names across all files
all_algs = set()
for sample_size, df in data_by_size.items():
    all_algs.update(df["Algorithm"].unique())
all_algs = sorted(all_algs)  # sort them for consistency

# Create one figure per algorithm, then save it
for alg in all_algs:
    plt.figure()  # new figure for this algorithm
    
    # Plot coverage vs K for each data size
    for sample_size, df in data_by_size.items():
        # Filter rows for this algorithm
        subset = df[df["Algorithm"] == alg]
        
        # Group by K in case multiple runs exist, then sort by K
        coverage_by_k = subset.groupby("K")["CoverageFraction"].mean().sort_index()
        
        # Plot with a marker so we can see each point
        plt.plot(coverage_by_k.index, coverage_by_k.values, marker='o', label=f"N={sample_size}")
    
    # Configure legend, labels, title
    plt.legend()
    plt.xlabel("Max Parent-Set Size (K)")
    plt.ylabel("Coverage Fraction")
    plt.title(f"Coverage vs K: {alg}")
    plt.ylim(0, 1.05)  # coverage fraction is between 0 and 1
    
    # Save plot to the "plots" directory (e.g., "plots/greedy_coverage_plot.png")
    plt.savefig(f"/home/gulce/Downloads/thesis/data/coverage/survey/datapointsplots/{alg}_coverage_plot.png")
    
    # Close the figure to free memory (avoids piling up many open figures)
    plt.close()
#!/usr/bin/env python3
import argparse
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def ensure_directory_exists(filepath):
    """Creates the directory for the filepath if it doesn't exist."""
    directory = os.path.dirname(filepath)
    if directory and not os.path.exists(directory):
        os.makedirs(directory)

def main():
    parser = argparse.ArgumentParser(
        description="Visualize CSV data as a heatmap of CoverageFraction by Algorithm and K."
    )
    parser.add_argument("csv_file", help="Path to the CSV file.")
    parser.add_argument("--metric", default="CoverageFraction",
                        help="CSV column to use as the heatmap values (default: CoverageFraction).")
    parser.add_argument("--xcol", default="K",
                        help="CSV column for the x-axis (default: K).")
    parser.add_argument("--ycol", default="Algorithm",
                        help="CSV column for the y-axis (default: Algorithm).")
    parser.add_argument("--save", type=str,
                        help="Optional path (including filename) to save the heatmap image (e.g., heatmap.png).")
    args = parser.parse_args()

    # Load the CSV file
    df = pd.read_csv(args.csv_file)
    
    # Pivot the DataFrame to have 'Algorithm' as rows and 'K' as columns with values from 'CoverageFraction'
    pivot_df = df.pivot_table(index=args.ycol, columns=args.xcol, values=args.metric, aggfunc="mean")
    
    # Sort the columns (K values) if they are numeric
    pivot_df = pivot_df.sort_index(axis=1)

    plt.figure(figsize=(8, 6))
    sns.heatmap(pivot_df, annot=True, fmt=".4f", cmap="YlGnBu",annot_kws={"fontsize": 8} )
    plt.title(f"Heatmap of {args.metric} by {args.ycol} vs. {args.xcol}")
    plt.xlabel(args.xcol)
    plt.ylabel(args.ycol)
    plt.tight_layout()
    
    if args.save:
        ensure_directory_exists(args.save)
        plt.savefig(args.save)
        print(f"Heatmap saved as {args.save}")
    else:
        plt.show()

if __name__ == "__main__":
    main()
import os
import pandas as pd
import matplotlib.pyplot as plt

files = {
    "Asia (8 Nodes)": "/home/gulce/Downloads/thesis/data/coverage/asia/asia_coverage_results_10000.csv",
    # "Sachs (11 Nodes)": "/home/gulce/Downloads/thesis/data/coverage/sachs/sachs_coverage_results_10000.csv",
    "Credit (12 Nodes)": "/home/gulce/Downloads/thesis/data/coverage/credit/credit_coverage_results_10000.csv",
    "EngineFuel (9 Nodes)": "/home/gulce/Downloads/thesis/data/coverage/enginefuel/enginefuel_coverage_results_10000.csv"
}

datasets = {}
for dataset_name, path in files.items():
    datasets[dataset_name] = pd.read_csv(path)

all_algorithms = sorted(
    set().union(*(df["Algorithm"].unique() for df in datasets.values()))
)

output_folder = "/home/gulce/Downloads/thesis/data/coverage/nodenumber/10000"
os.makedirs(output_folder, exist_ok=True)

for alg in all_algorithms:
    plt.figure(figsize=(8, 5))
    
    for dataset_name, df in datasets.items():
        subset = df[df["Algorithm"] == alg]
        
        # Group coverage by the "K" in the CSV...
        coverage_by_k = subset.groupby("K")["CoverageFraction"].mean().sort_index()
        
        # But we know "K" means "K+1" in reality, so shift x-values by +1
        real_k = coverage_by_k.index   # <--- shift by 1
        coverage_values = coverage_by_k.values
        
        plt.plot(real_k, coverage_values, marker='o', label=dataset_name)
    
    plt.title(f"Coverage vs. (K+1): {alg}\n(Exact Parents, 10000 Data Points)")
    plt.xlabel("Exact Parent-Set Size = (CSV K) + 1")
    plt.ylabel("Coverage Fraction")
    plt.ylim(0, 1.05)
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    
    save_path = os.path.join(output_folder, f"{alg}_coverage_shifted.png")
    plt.savefig(save_path)
    plt.close()
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
csv_path = "/home/gulce/Downloads/thesis/data/fair/coverage_log_nVars=10_maxInDeg=4_alpha=1.0_smallData=5000_refData=50000_means.csv"
df = pd.read_csv(csv_path)
import matplotlib.colors as mcolors
# Pivot data for coverage_prior and coverage_gobnilp
pivot_prior = df.pivot(index='method', columns='K', values='coverage_prior')
pivot_gobnilp = df.pivot(index='method', columns='K', values='coverage_gobnilp')

# Generate filenames by replacing .csv with _prior.png and _gobnilp.png
base_filename = csv_path.replace('.csv', '')
output_prior_path = f"{base_filename}_prior.png"
output_gobnilp_path = f"{base_filename}_gobnilp.png"
# Here, we assume coverage ranges from 0 to 1. Adjust if your min/max coverage differ.
norm = mcolors.Normalize(vmin=0.5, vmax=1.0)
# Heatmap for Coverage w.r.t. Prior DAG
plt.figure(figsize=(16, 12))
sns.heatmap(pivot_prior, annot=True, fmt=".3f", cmap="YlGnBu", annot_kws={"fontsize": 12})
plt.title("Coverage w.r.t. Prior DAG", fontsize=18)
plt.xlabel("K", fontsize=16)
plt.ylabel("Algorithm", fontsize=16)
plt.tight_layout()
plt.savefig(output_prior_path, dpi=300)
plt.show()

# Heatmap for Coverage w.r.t. Gobnilp DAG
plt.figure(figsize=(16, 12))
sns.heatmap(pivot_gobnilp, annot=True, fmt=".3f", cmap="YlGnBu", annot_kws={"fontsize": 12})
plt.title("Coverage w.r.t. Gobnilp DAG", fontsize=18)
plt.xlabel("K", fontsize=16)
plt.ylabel("Algorithm", fontsize=16)
plt.tight_layout()
plt.savefig(output_gobnilp_path, dpi=300)
plt.show()
